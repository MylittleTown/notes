# 常见的卷积网络结构

## 1. LeNet（输入图像大小以32 * 32 * 1 灰度图为例，也称为LeNet-5，表示3层卷积和2层全连接层）

第一模块：包含5 * 5 的6 通道卷积和2 * 2 的池化。卷积提取图像中包含的特征模式（激活函数使用Sigmoid），图像尺寸从32减小到28。经过池化层可以降低输出特征图对空间位置的敏感性，图像尺寸减到14

第二模块：和第一模块尺寸相同，通道数由6增加为16。卷积操作使得图像尺寸减小到10，经过池化后变成5

第三模块：包含5 * 5的120通道卷积。卷积之后的图像尺寸减小到1，但是通道数增加为120.将经过第三次卷积提取到的特征图输入到全连接层。第一个全连接层的输出神经元的个数为64，第二个全连接层的输出神经元个数是分类标签的类别数。然后使用Softmax 激活函数即可计算每个类别的预测概率。

LeNet 卷积网络明显的缺陷：在输入图像的尺寸过大时，对应参数量过大，且计算相对缓慢

## 2. AlexNet(输入图像大小为224 * 224，在之后修改为227 * 227)

相比较于LeNet，AlexNet 具有更深的网络结构，包含5 层卷积和3层全连接，同时使用了如下三种方法改进模型的训练过程：

1. 数据增广：深度学习中常用的一种处理方式，通过对训练随机加一些变化，比如平移、缩放、裁剪、旋转、反转或者增减亮度等，产生一系列跟原始图片相似但又不完全相同的样本，从而扩大训练数据集。通过这种方式，可以随机改变训练样本，避免模型过度依赖于某些属性，能从一定程度上抑制过拟合
2. 使用Dropout 抑制过拟合
3. 使用ReLU 激活函数减少梯度消失现象

其中有四个模块：

第一模块：包含了11 * 11 步长为4的96通道卷积以及一个最大池化

第二模块：包含了5 * 5 的256 通道卷积以及一个最大池化

第三模块：包含了两个3 * 3 的384通道以及一个3 * 3 的256通道的卷积，后面加一个最大池化

第四模块：包含了两个4096通道输入的全连接层，每个全连接层后面加一个Dropout 层来抑制过拟合，以及还有最后一个1000 通道的全连接层

## 3. VGG（也称为VGG-16，表示网络结构中13层卷积和3层全连接层）

VGG 是通过使用一系列大小为3 * 3 的小尺寸卷积核和池化层构造深度卷积神经网络。具有结构简单、应用性极强而很受欢迎。注意的是，一系列卷积过程中使用same 填充方法，保证输出矩阵大小等于输入矩阵大小。

VGG 具有13层卷积和3层全连接层。VGG 网络的设计严格使用3 * 3 的卷积层和池化层来提取特征，并在网络的最后使用三层全连接层，将最后一层全连接层的输出作为分类的预测。在VGG 中每层卷积将使用ReLU作为激活函数，在全连接层之后添加dropout 层来抑制过拟合。

使用小的卷积核能够有效减少参数的个数，使得训练和测试变得更加有效。比如使用两层3 * 3 卷积层（维度为1 条件下，两层卷积使用过滤器的个数分别为$n_{c1},n_{c2}$，考虑到卷积过程中维度是不断增加的，有$n_{c1}<n_{c2}$参数个数计算：$(3 * 3 + 1)*n_{c1} + (3 * 3 + 1)*n_{c2} < 20n_{c2}$），可以得到感受野（输出图像的像素点对应原始图像的尺寸）为5 的特征图，而比直接使用5 * 5 的卷积层（维度为1条件下，根据卷积层后池化层通道数目的定义，有$n_c=n_{c2}$，参数个数计算：$(5 * 5 + 1)*n_c = (5 * 5 + 1)*n_{c2}$）需要更少的参数。由于卷积核比较小，可以堆叠更多的卷积层，加深网络的深度，这对于图像分类任务来说是有利的。VGG 模型证明增加网络的深度可以更好的学习图像中的特征模式。

VGG 网络结构中还有一个简单的原则，在每次卷积过程中过滤器的个数按照两倍增加，并且在池化层中不断减小宽度和高度。



通过前面几个经典模型的学习，可以发现随着深度学习的不断发展，模型的层数越来越多，网络结构也越来越复杂。从理论上来说，假设新增加的层都是恒等映射，只要原有的层学习得到的跟原模型一样的参数，那么新模型结构就能达到原模型结构的效果。换句话说，原模型的解只是新模型的**解的子空间**，在新模型解的空间里应该能找到比原模型解对应的子空间更好的结果。

但是实践表明，增加网络的层数之后，训练误差往往不降反升。

因此引入残差网络ResNet 来解决上述问题。

利用残差块的定义和数学性质，将残差块对应的两层加入到神经网络中，与没有这两层的网络相比，并不会非常影响神经网络的能力，因为对于它来说学习恒等函数非常容易。考虑残差块的定义有：
$$
a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(w^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})
$$


当向后传播公式的参数设置为0，上面的结构等价于恒等函数。换句话说，原模型的解属于新模型解的子空间。而当参数$w^{[l+2]},b^{[l+2]}$都学习得到有意义的东西的话，可能比原模型中$a^{[l]}$具有更好的特征；而由于新模型在$a^{l}$上能有效学习得到$a^{[l+2]}$，因此ResNet 在具有卷积神经网络的深度的同时，保证了不会因为增加了更多的参数而影响模型的性能



这里提一下关于1 * 1卷积核的作用，众所周知，在卷积过程中，每一次卷积都会使得数据宽度和高度下降且深度增加，同时增加数据的非线性程度使得网络可以学习到更复杂的函数形式，1 * 1卷积核能够在卷积过程中通过合理设置卷积核深度（过滤器的数量）得到的输出图像就能因此发生改变减小。例如在输入28 * 28 * 192的数据中，通过32个1 * 1 * 192 的卷积核输出得到的数据矩阵为28 * 28 * 32，从而达到降低深度，通道数的效果。



考虑到不同尺寸的卷积核能够学习不同的特征，Inception Net 的思路就是在同一个卷积层中引入不同尺寸的卷积核来提取图像不同尺度的信息，最后进行合并融合，可以得到图像更好的特征。

为了保证不同卷积核在卷积操作后得到的图像尺寸与输入图像尺寸保持不变，即使所有卷积核对应的卷积运算得到的输出结果维度相同，需要使用same 填充。

但是和其他卷积网络一样，Inception Net 也要考虑增加深度带来的计算成本增加的问题，下面以5 * 5 的卷积核为例：

考虑输入数据大小为28 * 28 * 192，其中深度为192，选用32个5 * 5 大小的卷积核进行卷积操作，其中每个卷积核的深度与输入数据的深度一致，即192，最后得到的输出大小为28 * 28 * 32。那么在上述过程中所需要计算的次数为（输出数据的象素个数 * 卷积核中的每个象素与输入数据的每个对应数据的一次乘法运算，即（28 * 28 * 32）*（5 * 5 * 192））。为了减小这个计算成本，特别引入了1 * 1 卷积核，来减小数据的通道数$n_c$。

**深度，也称为“通道数”，是原始输入的特征表示的大小（长度）**

计算成本计算：
$$
Computational\_cost = count\_of\_filter params * count\_of\_filter\_positions\\ * count\_of\_filters
$$
引入Depthwise Separable Convolution，深度上可分离卷积

深度上可分离卷积的思路是，设计过滤器通道数与输入数据通道数相同，且每次卷积操作都取同一通道序号下的数据，最后得到具有相同通道数的输出数据，我们暂且称为“中间数据”，之后将中间数据的值通过逐点卷积计算得到输出

逐点卷积的思路与上面深度上卷积类似，将中间数据（$n_{out}*n_{out}*n_c$）与1 * 1 * $n_c$大小的卷积核逐点相乘并求和，结果值存放于输出数据矩阵的对应位置，最后得到$n_{out}*n_{out}*n_c'$（其中$n_c'$表示1 * 1 * $n_c$的卷积核的数量）大小的输出

有研究分析指出，深度上可分离卷积的过程的计算成本相比正常卷积网络的成本比率计算公式为
$$
ratio = \frac{1}{n_c'}+\frac{1}{f^2}
$$
其中$n_c'$表示逐点卷积的卷积核的个数，也是输出数据的深度（通道数）；$f$表示深度上卷积使用的卷积核的尺寸大小



关于卷积网络中分辨率（Resolution，r 为放大倍率），网络深度（depth，d 为放大倍率）以及网络宽度（width，w 为放大倍率），实验得出结论：三个维度中任一维度的放大都可以带来精度的提升，但随着倍率越来越大，提升却原来越小；得到更高的精度以及效率的关键是平衡网络宽度，网络深度，图像分辨率三个维度的放缩倍率(d, r, w)

因此提出了**混合维度放大法**，该方法使用一个混合系数$\Phi$来来决定三个维度的放大倍率：
$$
depth:d = \alpha^{\Phi}\\
width:w = \beta^{\Phi}\\
resolution:r = \gamma^{\Phi}\\
s.t.\alpha*\beta^2*\gamma^2\approx 2\\
	\alpha\geq 1;\beta\geq 1;\gamma\geq 1
$$
其中，$\alpha, \beta, \gamma$均为常数，可通过网格搜索获得；混合系数$\Phi$可以人工调节。考虑到如果网络深度翻番那么对应计算量会翻番，而网络宽度或者图像分辨率翻番对应计算量会翻4番，即卷积操作的计算量（FLOPS）与$d, w^2, r^2$成正比，因此上图中的约束条件中有两个平方项。

网格搜索方法：首先固定混合系数$\Phi$为1，即设定计算量为原来的2倍，在这样一个小模型上做网格搜索，得到最佳系数为$\alpha=\alpha_0,\beta=\beta_0,\gamma=\gamma_0$；固定$\alpha=\alpha_0,\beta=\beta_0,\gamma=\gamma_0$，使用不同混合系数$\Phi$来放大初代网络得到一系列EfficientNet 模块



这里介绍一个transfer learning，指的是基于已有的卷积网络模型，根据训练集数据量大小，确定固定卷积层参数的数量（我们可以通过设置这些需要固定的卷积层的参数为0等常数，保证其对后续需要训练的参数不会造成影响），通过训练集训练得到剩余卷积层以及全连接层的参数，最后根据自身问题的分类需求修改softmax 函数。

数据越多，所冻结的层数可以越少，自己训练的层数可以越多。这个思路让我们可以根据已有的训练集数据量大小，确定所需要的网络规模



**数据增强**：

最简单的数据增强方式应该是（对图片）做垂直镜像，简单来说，如果原图符合一种模板，那么通过水平翻转或者镜像后的图片应该也符合相同的模板。如果镜像操作保留了我们试着识别的任何图像内容，这将是一种很好用的数据增强技术。

另一种很常见的数据增强方式是随机裁剪。通过对原始图片中随机不同区域进行剪裁获得不同的示例来扩充我们的训练集。但是需要注意的是，有时候随机裁剪不是最好的数据增强方式，因为在选取裁剪区域的时候如果没有包含足够用来识别或者训练的特征，那么裁剪得到的训练集是没用的，所以通过随机裁剪进行数据增强在裁剪区域面积足够大的时候效果更好。

上面两种方法在数据增强的过程中都保留了原始图片的数据，第二类常用的数据增强方式是色彩变化。例如在原始图片中，向R, G, B 三种通道中增加不同的扰动，例如R+20, G-20, B+20，增加了红河蓝色通道的值，减小了绿色通道值。通过不同的扰动组合能获得不同的训练示例。这种做法能够让我们的学习算法在应对图像色彩变化时健壮性更好

其中一种色彩干扰的算法是PCA，即主成分分析。思路是通过增加或减少原始图像的主要构成的颜色通道（RGB，红，绿，蓝），对其他颜色通道修改较小，以此来保证整体和之前相同的着色

还有一种方法叫做“多重剪切”，思路是将原始图片反转后形成拷贝图片，分别对两者做如下操作，在中心区域选取一个方框面积的图像，并在原图中四个角选取相同大小的图像，总共有10个剪切图像，所以也称为“10次剪切”。这里对剪切次数没有很多限制，多重剪切的本质就是选取原图中的部分区域在保留原本可识别特征的前提下扩大训练集