### 评估假设

我们已经知道仅仅是因为这个假设具有很小的训练误差，并不能说明它一定是一个好的假设，如果这是一个过拟合假设，当我们推广到新的训练样本上就可能会出现很大误差。那么，怎么样判断一个假设是否过拟合呢？对于简单的模型（指训练样本的特征量很小），我们可以画出假设函数然后观察，但对于一般的情况，具有很多特征的例子，想要通过画出假设函数图像来观察就变得很难甚至是不可能的。

下面介绍一个思路：交叉验证，增强模型的泛化能力。为了确保我们可以评价我们的假设函数，将原训练样本分成两部分，第一部分将成为我们的训练集，第二部分将称为我们的测试集，一种典型的分割方法将所有数据分成训练集和测试集是按照7:3 的比例，将70% 的数据作为训练集，将30%的数据作为测试集，这里我们定义$m_{test}$表示测试样本的总数。

需要注意的是，如果原训练集的这组数据有某种规律或者顺序的话，最好根据分割比例从原数据集中随机选择

选择好了训练集和测试集，下面介绍一个典型的方法来训练和测试我们的学习算法。首先，需要对训练集进行学习得到参数$\theta$，具体来说，就是最小化训练误差（代价函数）$J(\theta)$，这里的$J(\theta)$是使用原数据中选择出来的70% 的数据得到的，也就是仅仅是训练数据。接下来需要计算测试误差，我们定义$J_{test}(\theta)$来表示测试误差，我们把从训练集中学习得到的参数$\theta$代入测试集的代价函数中来计算测试误差，例如我们在使用线性回归模型和平方误差标准时通常将测试集的测试误差写成
$$
J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\theta(x_{test}^{(i)})-y_{test}^{(i)})^2
$$
在测试逻辑回归模型时，同样学习得到参数$\theta$ 后，测试误差的表达式如下
$$
J_{test}(\theta)=-\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}(y_{test}^{(i)}log\,h_\theta(x_{test}^{(i)})+(1-y_{test}^{(i)})log\,h_\theta(x_{test}^{(i)}))
$$
目标函数和我们平常做逻辑回归的时候一样，唯一的区别就是这里我们使用的是$m_{test}$个测试样本

对于分类问题还有另一种形式的测试度量，我们称为0/1 分类错误，0/1 表示的是我们预测的分类是正确或错误的情况，我们可以如下定义一次预测的误差
$$
err(h_\theta(x),y)=\begin{cases}
1&if\quad h_\theta(x)\geq0.5,y=0\,or\,if\quad h_\theta(x)<0.5,y=1\\
0&otherwise
\end{cases}
$$
上面关于$err(h_\theta(x),y)=1$的两种情况都表明我们的假设对样本进行了误判（这里定义阈值为0.5）一种情况是预测结果更趋向于1，但实际上是0，或者说假设预测是0，但样本的实际的标签却是1。然后我们就能应用错误分类误差来定义测试误差，也就是
$$
Test\,error=\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}err(h_\theta(x_{test}^{(i)}),y_{test}^{(i)})
$$
这实际上就是我们假设函数误标记的那部分测试集中的样本，我们可以用这个来定义测试误差

### 模型选择和训练集，验证集，测试集

模型选择问题包括确定对一个数据集最合适的多项式次数，怎样选用正确的特征来构造学习算法，选择学习算法中的正则化参数$\lambda$。

首先我们将从选择合适的多项式次数来决定合适的模型，这里定义d 表示多项式次数，假设有10个模型（仅多项式次数不同）来选择，如下
$$
h_\theta(x)=\theta_0+\theta_1x\\
\quad \quad \quad h_\theta(x)=\theta_0+\theta_1x+\theta_2x^2\\
\quad \quad \quad \quad \quad h_\theta(x)=\theta_0+\theta_1x+\cdots+\theta_3x^3\\
\vdots\\
\quad \quad \quad \quad \quad h_\theta(x)=\theta_0+\theta_1x+\cdots+\theta_{10}x^{10}
$$


在之前的学习中，我们通常会使用训练集来学习算法，拟合模型，在加入了“测试集”这一概念后可以评估假设函数是否存在过拟合。但是在选取合适的模型时，我们分别计算每个多项式次数对应的模型的测试误差然后选出较小的测试误差对应的模型，但是测试误差较小的模型在测试集中的拟合情况仍然不能公平的估计出这个假设（模型）的泛化能力。其原因在于，我们在测试集上根据代价函数选取模型时实际上**拟合了一个额外的参数d，也就是多项式的次数**，我们用测试集拟合了参数d，选择了一个能够最好的拟合测试集的参数d 的值，因此我们的参数向量在测试集上的性能很可能是对泛化误差过于乐观的估计，这里的乐观指的就是“我们选择了测试误差相对较小”的模型，**测试误差小在这里只能说明这个多项式次数对应的模型在测试集上具有较好的表现，但不具备泛化能力**。

总结下来就是，用测试集拟合得到的参数d，再在测试集上评估假设就不公平了，因为用测试集拟合到的参数（用测试集选择了多项式的次数），所以假设很可能对于测试集的表现好过对于新的它没见过的样本，而后者才能体现模型的泛化能力。

为了解决模型选择出现的问题，我们通常会将一个给定的数据集分为三个部分，训练集，交叉验证集（有时候也叫做验证集），测试集，典型的分配比例为60%训练集，20%为交叉验证集，剩余20%为测试集。这里我们定义$m_{cv}$表示交叉验证样本的总数，$(x_{cv}^{(i)},y_{cv}^{(i)})$来表示第i 个交叉验证样本，总结下来三个部分的数据集分别对应三个误差表达式：
$$
J_{train}(\theta)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2\\
J_{cv}(\theta)=\frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}(h_\theta(x_{cv}^{(i)})-y_{cv}^{(i)})^2\\
J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\theta(x_{test}^{(i)})-y_{test}^{(i)})^2
$$
定义和前提条件完成后，当我们面对上面关于多项式次数的模型选择问题时，我们要做的就是用验证集来选择模型，而不是用原来的测试集。具体来讲，首先要选取第一种假设，即多项式次数d = 1，第一个模型，然后最小化代价函数，得到对应多项式次数为一次的模型的参数向量$\theta$，对应到上面10个多项式次数对应的假设，$\theta^{(k)}$来表示多项式次数为k 的时候最小化代价函数得到的参数向量。接下来用交叉验证集来测试，计算出$J_{cv}(\theta)$来观察这些假设模型在交叉验证集上的表现如何，然后选择交叉验证误差最小的那个假设作为我们的模型，最后用第三部分测试集来衡量或者估计算法选出的模型的泛化误差。

这里有一点要说明的是，当测试集足够大（样本量足够大的时候）确实将交叉验证误差和测试误差视为相同选取的模型也许表现也不错，但是不建议这种只分成训练集和测试集的方法做模型选择。

### 诊断偏差与方差

当我们运行一个学习算法时，如果这个算法的表现不理想，那么多半是出现两种情况，要么是偏差比较大，称为“欠拟合”，要么是方差比较大，称为“过拟合”，这里的方差我们可以理解为过拟合情况下假设函数的模型曲线能完美贴合每一个样本但是同时曲线为了尽可能贴合样本对应的点，上面也会有很多毛刺，这些毛刺表现出该假设的输出之间差值大，数值抖动，即方差大。

下面我们将介绍多项式次数与数据集误差之间的关系，这里选择训练误差和交叉验证误差

随着我们增大多项式次数，我们对训练集的拟合越来越好，也就是如果多项式次数等于1，则对应较大的训练误差，而如果多项式次数很高时，训练误差则会很低，甚至可能等于0，因为训练集拟合的会很好；如果我们观察测试集误差的话，我们会得到一个和交叉验证误差很类似的结果，我们知道如果多项式次数为1 的话，意味着用一个很简单的函数来拟合数据，也许不能很好的拟合训练集，我们会得到一个较大的交叉验证误差，如果用中等大小次数的多项式来拟合时，那么我们会得到一个更小的交叉验证误差，因为我们可能找到一个能够更好拟合数据的次数，同样的反过来，如果多项式次数太大，那么假设模型又过拟合了，我们就会得到一个较大的交叉验证误差。

值得注意的是，测试和交叉验证的误差要比训练误差高一点，因为通过训练集学习得到的模型参数应该能最小化代价函数的，相比较额外的数据样本更拟合训练集自身的数据集样本。

最后我们可以获得如下所示

![交叉验证误差和训练误差关于多项式次数的学习曲线](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%8D%81%E4%B8%80%E5%8D%81%E4%BA%8C%E7%AB%A0-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%AF%AF%E5%B7%AE%E5%92%8C%E8%AE%AD%E7%BB%83%E8%AF%AF%E5%B7%AE%E5%85%B3%E4%BA%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%AC%A1%E6%95%B0%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF.png)

交叉验证误差比较大的情况，对应着曲线中的两边的高点，而左边的高点对应的就是高偏差的问题，也就是我们使用了一个过于小的多项式次数，但实际上我们需要一个较高的多项式次数来拟合数据；相反的，右边这一端对应的是高方差问题，也就是说多项式次数对于我们的数据集来说太大了。

具体的说，对于高偏差的情况，也就是对应欠拟合的情况，我们发现交叉验证误差和训练误差都会很大，因此**如果我们的算法有偏差问题的话，那么训练误差将会比较大，同时交叉验证误差也会很大，很接近训练误差**，也许会比训练误差稍微大一些；反过来，**如果算法存在高方差的问题，我们会发现训练误差会很小，这代表我们对训练集数据拟合的非常好，而交叉验证误差或者说交叉验证集对应的代价函数的值将会远远大于训练误差**

下面我们将讨论偏差，方差和算法的正则化之间的关系，以及正则化是如何影响偏差和方差的。

这里给出一个假设函数以及为了防止过拟合使用正则化后的代价函数表达式
$$
h_\theta(x)=\theta_0+\theta_1x+\theta_2x^2+\cdots+\theta_nx^n\\
J(\theta)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\frac{\lambda}{2m}\sum_{j=1}^m\theta_j^2
$$
和之前使用正则化一样，正则化项的求和范围照例取为j 等于1 到m 而非0 到m。考虑三种情形

第一种情形是正则化参数$\lambda$的取值非常大，在这种情况下，参数$\theta_1,\theta_2,\cdots$等等将会被“惩罚”很重，其结果是这些参数在最小化代价函数后大部分都接近于0，并且这个假设函数$h(x)$将等于或者近似等于$\theta_0$（在图像中近似为一条水平直线），因此这个假设出于高偏差，对数据集严重欠拟合；另一种情形是如果我们使用非常小的正则化参数$\lambda$，比如说$\lambda=0$，在这种情况下，如果我们要拟合一个高阶多项式的话，通常会出现过拟合的情况，在这种情况下，在拟合一个高阶多项式时，如果没有进行正则化或者正则化程度很小的话，我们通常会得到高方差，过拟合的结果，因为通常来说$\lambda$的值等于0相当于没有正则化，因此会对假设过拟合；第三种情形当我们取一个大小适中的正则化参数$\lambda$的值时，我们才能得到一组对数据拟合比较合理的$\theta$参数值，这里的合理即对训练集样本拟合较好同时具有一定泛化能力。

下面我们将回到模型选择的问题上，为了选择出一个最合适的正则化参数$\lambda$的值，我们还是需要引入训练集，交叉验证集和测试集的概念，但是需要注意的一点是，在学习算法的目标函数（代价函数）中我们增加了正则化项，但是在模型选择的过程中，对于原数据集分割出来的三组数据的误差计算表达式中不考虑正则化项，因为正则化项是为了调整参数以消除过拟合或欠拟合问题的，不算误差。那么我们就定义如下训练误差，交叉验证误差和测试误差：
$$
J_{train}(\theta)=\frac{1}{2m_{train}}\sum_{i=1}^{m_{train}}(h_\theta(x_{train}^{(i)})-y_{train}^{(i)})^2\\
J_{cv}(\theta)=\frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}(h_\theta(x_{cv}^{(i)})-y_{cv}^{(i)})^2\\
J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_\theta(x_{test}^{(i)})-y_{test}^{(i)})^2
$$
对于使用正则化的模型，我们通常有一系列会试的$\lambda$值，$0,0.01,0.02,0.04,0.08,\cdots,10$，通常将步长设为2倍速增长，直到一个比较大的值，这一系列的$\lambda$的值对应了不同的备选模型，对于每一个模型我们最小化代价函数会得到某个参数向量$\theta$，按照同样的操作我们会得到一系列的参数向量对应的模型，然后我们将用交叉验证集计算每个模型的交叉验证误差来评估它们，也就是$J_{cv}(\theta)$，然后选择交叉验证误差最小的那个模型作为最终选择。当然，我们还可以用测试集来计算最终选择的模型的测试误差来评估这个模型的泛化能力。

总结来说，和之前模型选择过程中拟合额外的参数多项式次数d 类似，我们交叉验证集来拟合这个额外参数，并预留了单独的测试集来更准确的估计出最终选择的模型的参数向量$\theta$对于新样本的泛化能力。

下面将介绍当改变正则化参数$\lambda$时，交叉验证误差和训练误差如何变化，也就是当我们改变正则化参数时，假设在训练集以及在交叉验证集上的表现如何。

如果正则化参数$\lambda$很小，那也就是说我们几乎没有使用正则化，因此我们有很大可能出于过拟合，但是因为没有额外参数或者说此时额外参数$\lambda$对目标函数（代价函数）的影响较小，所以对训练集拟合相对较好，$J_{train}(\theta)$的值会较小，同时由于对数据过拟合，交叉验证误差$J_{cv}(\theta)$的值会很大；而如果$\lambda$的值很大时，我们很有可能出现高偏差的问题，对训练集不能很好的拟合，此时$J_{train}(\theta)$的值比较大，同时，$\lambda$的值很大时，会出现欠拟合问题，交叉验证误差$J_{cv}(\theta)$也会很大；同样的，总会有中间的某个$\lambda$值这时表现的刚好合适，此时的交叉验证误差和测试误差都很小

### 学习曲线

学习曲线是一种检查学习算法运行是否一切正常，或者希望改进算法的表现的很好的工具。通常使用学习曲线来判断某一个学习算法是否处于偏差，方差问题或者二者皆有，它描述的是给定模型（多项式次数，正则化参数等）的条件下训练误差，交叉验证误差以及测试误差关于训练集样本容量的增加的变化曲线。

一般来说，给定假设函数，也就是多项式次数给定，当训练样本容量很小的时候，训练误差也会很小，因为如果训练集很小，那么很容易就能把训练集拟合到很好，甚至拟合的天衣无缝，随着训练集容量的增大，平均训练误差在增大。

然后我们来考虑交叉验证误差，当训练集容量变化时交叉验证误差的变化情况，当然，在这里我们也可以理解为交叉验证误差就是在没有见过的交叉验证集上的误差，是相当于训练集来说的新样本。当训练集很小的时候，泛化程度不会很好，意思是不能很好的适应新样本，因此这个假设就不是一个理想的假设，只有当我们使用一个更大的训练集时才有可能得到一个能够更好拟合数据的假设，因此**交叉验证误差和测试误差都会随着训练集样本容量的增加而减小**，因为当我们使用的数据越多，在多项式次数给定，也就是模型算法的参数数量给定的条件下，越能获得更好的泛化表现，因此数据越多，越能拟合出合适的假设。

下面来介绍高偏差或者高方差的情况下，学习曲线又会变成什么样子。

现在我们给定假设函数，即多项式次数，比如d = 1，绘制出在不同的训练集容量的情况下假设函数对样本集的拟合情况，如下

![假设函数在不同训练集样本容量下的拟合情况](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%8D%81%E4%B8%80%E5%8D%81%E4%BA%8C%E7%AB%A0-%E5%81%87%E8%AE%BE%E5%87%BD%E6%95%B0%E5%9C%A8%E4%B8%8D%E5%90%8C%E8%AE%AD%E7%BB%83%E9%9B%86%E6%A0%B7%E6%9C%AC%E5%AE%B9%E9%87%8F%E4%B8%8B%E7%9A%84%E6%8B%9F%E5%90%88%E6%83%85%E5%86%B5.png)

不难发现，交叉验证误差或测试误差（这里不区分两者是因为对于训练集样本来说，原数据集分割剩下的两个部分的数据集都是新样本，用于判断训练集生成的学习算法的泛化能力时没有区别）在训练集样本容量很小的时候，比如只有一个样本，表现的当然很不好，不具备很好的泛化能力，而当训练集样本数增大到某个值的时候，我们就能通过优化算法找到最有可能拟合数据的假设函数的曲线或直线，并且此时即便继续增大训练集样本容量，还是会得到一条差不多的假设函数的曲线图像，因此价差验证误差或者测试误差就会变为水平而不再随着训练集样本容量的变化而变化，这种情况就要增加多项式次数或者增加神经元，也就是说，只要达到或超过一定数量的训练样本我们就能得到最能拟合数据的曲线；

至于训练误差，同样，训练误差在训练集样本容量很小的时候也是很小的，而在高偏差的情形（训练误差，交叉验证误差均很大且接近）中，训练误差会逐渐增大最后接近于交叉验证误差，这时因为当我们给定的假设函数的参数很少又有很多数据（训练集样本）时，训练集拟合出来的曲线（假设函数）的泛化能力会很好，训练集和交叉验证集的误差将会非常接近。高偏差问题下，可以由很高的交叉验证误差和训练误差反映出来，也就是说，最终我们会得到一个值比较大的$J_{cv},\,J_{train}$

这也得出一个很有意思的结论，**如果一个学习算法有高偏差，随着我们增加训练样本，会发现交叉验证误差不会明显下降，而是基本变成平稳的**。所以如果学习算法正处于高偏差的情形，那么选用更多的训练集数据对于改善算法表现无益，类似上面举的关于给定多项式次数d = 1 的例子在不同训练集样本容量时的拟合曲线情况，误差依旧很大。

接下来我们再来看看当学习算法正出现高方差时训练误差，交叉验证误差和测试误差关于训练集样本容量的变化是什么样子。

如果我们的训练集样本容量很小，选用很高次的多项式来拟合，并且这里假设我们使用一个很小的正则化参数$\lambda$表示基本不使用正则化来避免过拟合问题（可以不是0，但是足够小的$\lambda$值），结果我们会发现我们对这组数据拟合的很好，并且这个假设函数会对数据过拟合，所以如果训练集样本容量很小，我们的训练误差$J_{train}(\theta)$会很小，随着训练集样本容量的增加，可能仍然会有些过拟合，但此时要对数据很好的拟合就会变得更加困难。总结一下就是**，给定模型的多项式次数的情况下（假设函数给定）且出现高方差问题（过拟合，泛化能力低），随着训练集样本容量的增大，训练误差$J_{train}(\theta)$的值也会随之增大**，因为当训练样本越多的时候，就越难把训练集数据拟合的很好，但总的来说训练误差还是很小（这只是因为过拟合）；至于交叉验证误差，**在高方差的情形中，假设函数对数据过拟合，因此交叉验证误差将会一直很大，随着训练集样本容量增加会有略微下降，但是降不下来**，即便我们选择一个中等大小的训练集样本容量，因此算法处于高方差情形下最明显的一个特点就是在训练误差和交叉验证误差之间有很大的差值。

值得一提的是，在高方差的情形中，如果我们考虑增大训练集样本容量，交叉验证误差的学习曲线会持续缓慢下降，也就是说使用更多的训练集数据对改进算法是有帮助的

### 误差分析

之前我们介绍了通过画学习曲线以及检验误差来找出我们的算法是否存在高偏差或高方差的问题，或者一些其他问题，在作出这些分析后再来决定是否使用更多的数据或者特征等等改进优化的方法。因为在缺乏各种证据的情况下，我们没有画出学习曲线，也就并不能预知是需要更多的特征还是需要更多的数据或者是别的东西，也就很难计算出应该把时间花在哪些地方来优化改进算法，所以很多时候应当先进行一次简单快速的实现，然后画出学习曲线来帮助我们进行之后的判断。

这种思想告诉我们应当用实际的证据来指导我们的决策，来决定把时间花在哪里，而不是仅凭直觉。

误差分析是一种手动的去检查算法所出现的失误的过程，它能引导你走向最有效的道路，这也是为什么推荐先快速实现一个简单粗暴的算法，我们真正要做的事是找出这种算法最难以分类的样本，对于不同的算法，不同的学习算法而言，对它们造成困难的样本总是相似的，通过一个简单粗暴的算法实现，我们就能很快找到算法的不足所在和难以处理的样本类型，然后把精力集中在它们身上

下面我们将介绍在改进学习算法时提供一个对学习算法进行数值估计的工具。意思就是说，当我们改进学习算法时，如果我们的学习算法能够返回一个数值评价指标来估计算法执行的效果将会很有帮助。这个数值将告诉我们我们的学习算法效果有多好。

例如交叉验证错误率，通过交叉验证算法修改前后各自的错误率来估计算法的效果，错误率的减少能让我们很快的判断出算法是否需要修改，而这里提到单一规则的数值评价指标就是交叉验证错误率，它能直接告诉我们我们提出的新想法能提高还是降低学习算法的表现。当然，需要注意的是，推荐在交叉验证集上来做误差分析，而不是在测试集上，在测试集上做误差分析从数学的角度来说是不合适的。

总结来说，首先实现一个简单粗暴的算法，不用担心过于简单或者效果太差，而是尽可能快的实现出一个算法，一旦有了一个初始的算法实现，我们就能使用一个强有力的工具来帮助我们决定下一步该怎么办。第一步，看看它所造成的错误，通过误差分析来看看它出现了什么失误，然后以此决定之后的优化方法；第二部，假如说已经有了一个简单粗暴的算法实现，又有了一个数值评价指标，这些能帮助我们来试验新的想法，帮助我们快速发现我们所试验的这些想法是否能提高算法的表现，这能让我们更快的决定我们的算法应该放弃什么，应该包含什么。

### 不对称性分类的误差评估

之前提到了误差分析以及设定误差度量值的重要性，也就是说设定某个实数来评估我们的学习算法并衡量它的表现，有了算法的评估和误差度量值，我们就需要注意如何选择合适的误差度量值，这有时会对于我们的学习算法造成非常微妙的影响。

下面需要引入一个概念：偏斜类。这种情况发生在正例和负例的比率非常接近于一个极端的情况，例如正样本的数量与负样本的数量相比非常非常少，换言之，一个类中的样本数与另一个类的数据相比多很多，这个时候假设函数的输出值，也就是模型的预测值恒定为某一个类，如果以交叉验证错误率作为数值评估指标，此时的算法可能表现也会非常好，但实际上并不是一个好的分类模型。因此使用分类误差或分类精确度这种单一评估度量虽然能帮助我们迅速决定我们是否需要对算法作出一些改进，但是在偏斜类的情形中，无法判断我们对算法的改进是有用的，还是仅仅将算法改成了总是预测一个值或类别的没有泛化能力的不好的模型。

所以接下来我们要介绍几种不同的评估度量值，其中一种评估度量值叫做查准率和召回率，为了介绍这个概念，我们还需要引入几个定义，在二分类问题中，如果有一个样本它实际所属的类是1，预测的类也是1，那么我们把这个样本叫做**真阳性(True positives)**，意思是说我们的学习算法预测这个值为阳性，实际上这个样本也确实是阳性；如果我们的学习算法预测某个值是阴性，等于0，实际的类也确实属于0，那么我们把这个叫做**真阴性(True negatives)**；如果我们的学习算法预测某个值等于1，但是实际上它等于0，这个叫做**假阳性(False positives)**；当我们的算法预测值为0，但是实际值是1，我们称它为**假阴性(False negatives)**。可以参考如下图示

![引入假阳性等描述预测结果的指标](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%8D%81%E4%B8%80%E5%8D%81%E4%BA%8C%E7%AB%A0-%E5%BC%95%E5%85%A5%E5%81%87%E9%98%B3%E6%80%A7%E7%AD%89%E6%8F%8F%E8%BF%B0%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E7%9A%84%E6%8C%87%E6%A0%87.png)

这样我们就有了一个方式来评估算法的表现，需要计算两个数值，第一个叫做查准率，其含义是对于所有我们预测属于正例的样本集合中有多大比率的样本是真正属于正例样本的，用表达式来表示就是$Precision=\frac{True\,positives}{\#predicted\,positives}=\frac{True\,positives}{True\,positives+False\,positives}$，分母对应的是表格的第一行，从查准率的含义来看，查准率越高越好；另一个数值我们要计算的叫做召回率，它的含义是如果对于确实属于正例的样本有多大比率我们的预测结果就是它属于正例，其用表达式来表示就是$Recall=\frac{True\,positives}{\#actual\,positives}=\frac{True\,positives}{True\,positives+False\,negatives}$，分母对应的是表格的第一列，从召回率的定义来看，召回率越高越好。

通过计算查准率和召回率，我们能更好的知道分类模型的表现，具体的说，如果我们有一个算法，它的预测值总是某一个固定的值或者类，那么这个分类模型的召回率等于0，因为它不会有真阳性，因此我们就很快能发现这个分类模型不是一个好的模型。能肯定的是，拥有高查准率或者高召回率的模型是一个好的分类模型，并且这两个评估度量值在偏斜类的情形中也能很好的衡量模型的表现，这给予我们一个更好的评估值。

关于查准率和召回率的定义中需要注意的是，查准率和召回率总是习惯性的用预测值为出现的非常少的类或值。

类似于二分类扩展到多分类的问题，多分类问题中要计算每个分类的查准率和召回率，才更能描述模型的性能。

### 查准率和召回率的权衡

以逻辑回归模型举例，在二分类问题中，我们通常用阈值来计算样本属于某一分类的概率，也称为置信度，例如0.5，也就是说，在逻辑回归模型中$0\leq h_\theta(x)\leq 1$且
$$
y^{(i)}=\begin{cases}
1\quad h_\theta(x)\geq0.5\\
0\quad h_\theta(x)<0.5
\end{cases}
$$
当我们将阈值上调，当我们认为$P(y=1|\theta,x)\geq0.7$时认为该样本的预测值y等于1，换言之在我们非常确信的情况下才预测y 等于1，那么我们的回归模型会有较高的查准率（在给定样本集的条件下，虽然从查准率的表达式来看，分子和分母都因为阈值增加而减小导致无法迅速判断整个分式的结果是变大还是变小，但从查准率的定义来看，我们的阈值表示的是在预测某一个样本为正例的情况下该样本实际上是正例的比率，这个值在提高了阈值的时候一定是增加的），与之相反，这个回归模型会有较低的召回率（召回率的变化可以从分式表达式中体现，在样本集给定的条件下，分母，即实际分类为正例的数量是固定的，而预测为正例的人数因为阈值的提高而变少，所以整个分式的结果变小）

当我们希望避免出现过多的假阴性的样本时，具体来说就是要减少我们预测为负例实际上为正例的样本数量，这样的话，我们不再设置高的临界值，而是设的较低比如0.3，和上面的例子一样，我们可以推导出在设置了较低的临界值的情况下，这个回归模型会具有较低的查准率和较高的召回率

假设我们有三个不同的学习算法或者根据临界值的不同绘制了同一算法的三个不同的学习曲线，它们都对应着不同的查准率和召回率，我们应该如何决定哪一个算法是最好的？

不同于之前单一评估度量值通过一个具体的数字来反映算法模型质量的好坏，但是查准率和召回率作为评估度量值时我们有了两个可以判断的数字，不能迅速根据某一个评估度量值的大小来判断模型的表现。

因此我们引入一个单一评估度量值F 值来结合查准率和召回率，其表达式如下
$$
F_1\,score=2\frac{PR}{P+R}
$$
其中P 表示的是查准率，R 表示召回率。将该表达式进行变换（注意这里不是等价变换，P 和R 可以等于0）：
$$
F_1\,score=\frac{1}{\frac{1}{2}(\frac{1}{P}+\frac{1}{R})}
$$
可以发现这其实是查准率P 和召回率R 的倒数平均数，又称为调和平均数，调和平均数主要是用来解决在无法掌握总体单位数（频数）的情况下，只有每组的变量值和相应的标志总量，而需要求得平均数的情况下。调和平均数具有以下几个特点，第一是调和平均数易受极端值的影响，且受极小值的影响比受极大值的影响更大；第二是只要有一个标志值为0，就不能计算调和平均数；第三是当组距数列有开口组时，其组中值即使按照相邻组距计算，假定性也很大，这时的调和平均数的代表性很不可靠；第四是调和平均数应用的范围很小，在实际中，往往由于缺乏总体单位数的资料而不能直接计算算术平均数，这时需用调和平均数

相比较算数平均数，同样受极端值影响，但是受极小值影响更大符合我们在结合查准率和召回率来评估并选择模型的标准，当查准率或者召回率过低，接近于0时，该模型的F 值会变得很小而被淘汰。

### 支持向量机

首先我们来介绍根据逻辑回归模型构建支持向量机的思路，下面是逻辑回归模型中使用的代价函数$J(\theta)$最小化：
$$
min\,J(\theta)=min\,\frac{1}{m}[\sum_{i=1}^my^{(i)}(-log\,h_\theta(x^{(i)}))+(1-y^{(i)})(-log(1-h_\theta(x^{(i)})))]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2
$$
对于支持向量机而言，我们要做的实际上就是将逻辑回归模型中单个样本的Cost 函数替换为和逻辑回归模型中Cost 函数的曲线形状相似的多段直线，从直观上来说，以直代曲，它和逻辑回归的效果相似，但是相比较原Cost 函数的激活函数Sigmoid 函数具有计算上的优势，并且使得之后的优化问题变得简单，更容易解决。替换后Cost 函数图像如下![支持向量机的Cost函数与原Cost函数](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%8D%81%E4%B8%80%E5%8D%81%E4%BA%8C%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84Cost%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8E%9FCost%E5%87%BD%E6%95%B0.png)

两幅图分别对应的是当样本标签为1 或0 的代价函数图像，定义为$Cost_1(z)$和$Cost_0(z)$，下标表示在代价函数中y = 1 或者y = 0

接下来开始修改原代价函数，按照惯例，对于支持向量机来说，一些东西的写法会略有不同，比如代价函数的参数。首先我们要去掉$\frac{1}{m}$这一项，事实上，对于算法模型来说，$\frac{1}{m}$这一项是常数，所以这同样能得到$\theta$的最优值，换言之，在解决这个最小化问题的时候，无论前面是否有$\frac{1}{m}$这一项，我们最后都能得到相同的$\theta$最优值。

第二步，将原代价函数中看作两部分，求和项和正则化项，按照结构我们可以分别设为A 和B写成如下形式：$A+\lambda B$，其中$\lambda$表示正则化参数，这里不考虑正则化参数对优化目标的影响而视为常数，原式可以变换成$CA+B$，其中C 是不包含参数向量$\theta$或者样本$(x^{(i)},y^{(i)})$的项，依然不会影响优化目标。

通过上面两步的变换我们将逻辑回归模型的代价函数的表达式变换为如下形式：
$$
min\,J(\theta)=min\,C\sum_{i=1}^m[y^{(i)}Cost_1(\theta^Tx^{(i)})+(1-y^{(i)})Cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{j=1}^n\theta^2_j
$$
值得注意的是，支持向量机中对Cost 函数的替换导致它不像逻辑回归模型的假设函数输出的是概率，相对的在学习得到参数值$\theta$后我们的假设函数的输出是直接预测1 或0，也就是
$$
h_\theta(x)=\begin{cases}
1\quad if\:\theta^Tx\geq0\\
0\quad otherwise
\end{cases}
$$
这里的假设函数$h_\theta(x)$还是逻辑回归模型的假设函数

有时人们会把支持向量机叫做大间距分类器，我们通过根据逻辑回归模型的代价函数的图像做近似直线，如图所示

![支持向量机对Cost函数的近似](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%8D%81%E4%B8%80%E5%8D%81%E4%BA%8C%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E5%AF%B9Cost%20%E5%87%BD%E6%95%B0%E7%9A%84%E8%BF%91%E4%BC%BC.png)

左边的图表示的是$Cost_1(z)$，右边的表示的是$Cost_0(z)$，其中下标表示的是样本是正例，即y = 1 还是负例y = 0，可以看出，对于样本标签y = 1 的Cost 函数，当z，也就是$\theta^Tx\geq 1$时代价函数最小，同理，样本标签y = 0，满足$z\leq-1时$代价函数最小

需要注意的是，**这里的临界值1 和-1 是人为给定的，与我们模型中使用的Cost 函数的图像性质有关**，是我们根据逻辑回归模型的代价函数的图像拟合出来的近似的多段直线图像的属性，也是人为的属性，相应的，我们还可以是正例的代价函数的拐点在z = 2，负例的图像的拐点在z = -1.5，可以不对称。

回到临界点为z = 1 和z = -1 的例子中，这就相当于在支持向量机中构建了一个安全因子，一个安全间距，接下来我们来推导这个安全间距的含义

对于形如CA+B来表示代价函数的式子，当取C 非常大的时候，我们优化目标的时候将尽可能使得原式中第一项也就是A（求和项）的值最小，姑且认为我们通过选择参数来使得第一项A 等于0，而要满足这个，我们对于求和项涉及的每一个训练集样本都有如下条件：
$$
\theta^Tx^{(i)}\geq1\quad if\:y^{(i)}=1\\
\theta^Tx^{(i)}\leq-1\quad if\:y^{(i)}=0
$$
也就是说，当我们解决这个优化问题的时候，当我们最小化这个形如CA+B 的关于参数$\theta$的函数时，会得到一个决策边界（由两条直线组成，分别对应正例和负例分类），而支持向量机将会给出一个最合适的决策边界，而这个决策边界将会具有**最大间距**。支持向量机有关间距的概念定义为决策边界和训练样本的最小距离。这使得支持向量机具有鲁棒性，因为它在分离数据时会尽量用大的间距去分离

根据我们之前推导支持向量机时设定的条件，形如CA+B 的代价函数的C 取值非常大，而求和项A 作为描述每个训练集样本的Cost 函数，在C 非常大的时候对**异常点**会非常敏感。在之前对逻辑回归模型的代价函数变形的过程中，考虑C 的作用其实类似于$\frac{1}{\lambda}$，而$\lambda$是我们之前使用的正则化参数，上面关于支持向量机的特性也可以描述为在C 取值非常大，也就是当$\frac{1}{\lambda}$非常大或者$\lambda$非常小的时候，对异常点非常敏感，我们也可以用过拟合的知识来解释。

从数学的角度来看，决策边界$\theta^Tx=1$和$\theta^Tx=-1$实际上是和参数向量$\theta$正交的（因为$\theta^T\theta=0$，这里的0 实际上是零向量），也就是说，支持向量机优化目标的结果是想要一个有最大间距并且和支持向量机通过优化目标学习得到的参数$\theta$正交的决策边界，这句话定语很多，总结来说就是两个词“最大间距”“正交”。再来看看优化目标，当形如CA+B 的代价函数中C 的取值非常大的时候，支持向量机得到的参数$\theta$是让求和项A 尽可能小，接近于0，此时优化目标可以写成$min\,\frac{1}{2}\sum_{j=1}^n\theta_j^2=min\,\frac{1}{2}\parallel\theta\parallel^2$，原优化目标转换为需要参数向量$\theta$范数尽可能小，考虑此时求和项涉及的每个训练集样本需要满足的条件限制
$$
\theta^Tx^{(i)}\geq1\quad if\:y^{(i)}=1\\
\theta^Tx^{(i)}\leq-1\quad if\:y^{(i)}=0
$$
$\theta^Tx$作为向量的内积，它的值变大有两种方式：增大$\theta$的模，或减小向量夹角，而优化目标中的第二项需要$\theta$的模尽可能小，于是只能减小夹角

### 核函数

我们通常使用核函数改造支持向量机算法来构造复杂的非线性分类器。在非线性分类器中，决策边界往往是由很多复杂的多项式项组成，这些高阶项由原特征经过数学计算得到，例如$\frac{x_1}{x_2},x_1x_2^3,\cdots$，这些复杂的多项式项是一种得到更多特征的方式，但是我们可以有很多不同的特征选择或者可能存在比这些高阶多项式更好的特征，因为我们不能清楚的知道这些高阶项是不是我们真正需要的。所以我们需要引入更好的特征的选择来嵌入到假设函数中（理论上我们可以引入任何特征构成下面$\theta^Tf$的形式），例如
$$
\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1x_2+\theta_4x_1^2+\theta_5x_2^2+\cdots\geq0\\
\Longrightarrow\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+\cdots(f_1=x_1,f_2=x_2,f_3=x_1x_2,f_4=x_1^2,f_5=x_2^2,\cdots)
$$
下面我们介绍一个可以构造新特征$f_1,f_2,f_3,\cdots$的方法。假设训练样本具有两个特征$x_1,x_2$，在样本的特征空间（满足特征取值范围或其他要求的点构成的空间）中选取一些点，然后将这些点称为标记，这里假设只选取了三个点分别用$l^{(1)},l^{(2)},l^{(3)}$表示，然后我们将按照如下方式定义新的特征：
$$
f_1=similarity(x,l^{(1)})=exp(-\frac{\parallel x-l^{(1)}\parallel}{2\sigma^2})\\
f_2=similarity(x,l^{(2)})=exp(-\frac{\parallel x-l^{(2)}\parallel}{2\sigma^2})\\
f_3=similarity(x,l^{(3)})=exp(-\frac{\parallel x-l^{(3)}\parallel}{2\sigma^2})
$$
新的特征$f_1,f_2,f_3$分别定义为一种相似度的度量，即在给定训练样本实例x 的条件下度量训练样本x 与标记的相似度，调用的函数称为相似度函数，这个我们用于相似度度量的特殊公式也是相似度函数的一个示例，相似度函数用数学家的术语来说就是核函数，而这里的特殊公式在核函数的类型中又称为高斯核函数，从统计学的角度来分析这个表达式，每个高斯核函数上的点满足平均值为对应的标记点的向量（也可以理解为函数上的点在向量的每一个元素位置上的平均值是标记点向量对应位置上的值），而$\sigma$就是方差。

一般我们也不会将核函数写成similarity(x, l)，而是用k(x, l) 这个记号来表示核函数

在上面的例子中我们手动选择了三个标记点，每一个标记点会定义一个新的特征，也就是说，给定一个训练样本x，我们可以计算三个新的特征$f_1,f_2,f_3$

下面我们来看下核函数到底有什么作用，为什么这些相似度函数使用的特殊公式是有意义的。假设x 在特征空间中与其中一个标记点$l^{(1)}$非常接近，那么上面的特殊公式中的欧氏距离，也就是分子会接近于0，有$f_1\approx exp(-\frac{0^2}{2\sigma^2})\approx 1$，那么新特征$f_1$将会接近于1；相反的，如果实例x 离标记点$l^{(1)}$很远，此时特殊公式中的分子表示两者的欧式距离会变得非常大，那么$f_1\approx 0$

下面都是我的一些总结性的理解：

由于新特征$f_1,f_2,f_3$是由原特征空间的点经过相同的变化得到的，我们也可以理解为核函数实际上是在变换坐标轴，或者说是在构造新的特征空间。另外，新特征对应的假设函数看起来与线性回归模型的假设函数相似，但是由于$f_1,f_2,f_3$本身在原特征空间中是非线性的，所以新构造的分类器也是一个非线性分类器。

原始特征的值是特征空间某一点到坐标轴的向量（因为存在方向），那么这个特征对应的参数$\theta_i$对于与该坐标轴距离相等的点赋予的权重是相等的，所以$\theta^Tx$只能表现为线性；当我们在原特征空间中，新特征以欧氏距离作为度量时，度量值相等的点形成的图形不再是线性了。欧式距离在任何多维空间中都能成立并且表现为非线性，所以具备鲁棒性。当然，这有点像结果论了，很明显提出高斯核函数的思路不是因为欧氏距离的这个性质，欧氏距离只是高斯核函数具备的一个性质。

接下来我们将把核函数的应用一般化。在给定的训练集中我们取出m 个样本作为标记点，即$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},\cdots,l^{(m)}=x^{(m)}$，通过相似度函数得到m 个新的特征
$$
f_1=similarity(x,l^{(1)})\\
f_2=similarity(x,l^{(2)})\\
\vdots
$$
这样就能得到一个新的特征向量$f=\left[\begin{matrix}f_0\\f_1\\f_2\\\vdots\\ f_m\end{matrix}\right]$，其中增加了一项$f_0$等于1表示截距，在新的特征空间中，对于任意一个训练样本$(x^{(i)},y^{(i)})$的实例$x^{(i)}$都有新的特征值
$$
f_1^{(i)}=similarity(x^{(i)},l^{(1)})\\
f_2^{(i)}=similarity(x^{(i)},l^{(2)})\\
\vdots\\
f_m^{(i)}=similarity(x^{(i)},l^{(m)})\\
$$
其中根据核函数（相似度函数）的定义$f_i^{(i)}=similarity(x^{(i)},l^{(i)})=similarity(x^{(i)},x^{(i)})=1$，就这样，相比之前用$x^{(i)}$作为n 维或者n+1 维空间（考虑加入$x_0=1$）的向量来描述样本，我们现在可以用新的特征向量f 来描述训练样本。

下面我们将在新的特征空间中使用支持向量机。已经学习得到参数$\theta$后（变换特征空间前后需不需要计算原特征空间的参数向量有待确定），给定训练集和原特征空间，我们将计算得到新的m 维特征空间$f\in R^{m+1}$，给出新特征空间的决策边界
$$
h_\theta'(f)=\begin{cases}
1&\theta^Tf\geq0\\
0&otherwise
\end{cases}
$$
同时将优化目标的式子也变换到新特征空间中，如下
$$
min\,C\sum_{i=1}^my^{(i)}Cost_1(\theta^Tf^{(i)})+(1-y^{(i)})Cost_0(\theta^Tf^{(i)})+\frac{1}{2}\sum_{j=1}^n\theta_j^2
$$
值得注意的是，当我们使用核函数变换特征空间时，将所有训练集样本视为标记点，所以新的特征向量的维数n 其实等于m，也就是说，上面的式子可以写成
$$
min\,C\sum_{i=1}^my^{(i)}Cost_1(\theta^Tf^{(i)})+(1-y^{(i)})Cost_0(\theta^Tf^{(i)})+\frac{1}{2}\sum_{j=1}^m\theta_j^2
$$
由于支持向量机中的Cost 函数我们是将逻辑回归模型中的曲线拟合成了分段线性函数，所以套用高斯函数的代价函数优化过程计算量相比较逻辑回归模型中对数套用高斯函数要明显低很多，所以通常不在逻辑回归模型等其他算法模型中使用核函数

最后稍微说明一下在使用支持向量机时偏差和方差的权衡问题。在使用支持向量机的时候，其中一个要选择的事情是优化目标中的参数C，C 的作用与$\frac{1}{\lambda}$相似，而$\lambda$是逻辑回归算法中的正则化参数。所以当C 取值非常大时，对应的就是之前在逻辑回归模型中的$\lambda$取值非常小，近似于不使用正则化，这样就有可能得到一个低偏差但高方差的模型，更倾向于过拟合；当我们使用了较小的C，这对应着在逻辑回归问题中使用较大的$\lambda$，对应着一个高偏差但低方差的模型，更倾向于欠拟合

另外一个要选择的参数是高斯核函数中的$\sigma^2$，当高斯核函数中的$\sigma^2$偏大时，那么对应的相似度函数倾向于变得相对平滑，由于函数平滑且变化的比较平缓，因此我们更倾向于得到一个随着输入x 变化的缓慢的模型，这会给我们的模型带来较高的偏差和较低的方差；相反的，如果$\sigma^2$比较小，相似度函数会变化的很剧烈，特征的变化会变得不平滑，也就是**对特征值的变化非常敏感**，这样的话在新特征空间中的假设函数将会非常拟合训练集样本，最终得到的模型是低偏差和高方差的

一个使用核函数的注意事项是，如果我们有取值范围很不一样，尤其在大小方面，的特征变量，我们有必要在使用高斯核函数之前将这些特征变量的大小按照比例归一化，因为我们在高斯核函数中涉及计算两个特征向量的差值的范数，有$\parallel x-l\parallel^2$
$$
v=x-l\\
\parallel v\parallel^2=v_1^2+v_2^2+\cdots+v_n^2\\
=(x_1-l_1)^2+(x_2-l_2)^2+\cdots+(x_n-l_n)^2
$$
其中$(x_1,x_2,\cdots,x_n)$以及$(l_1,l_2,\cdots,l_n)$无论是训练集样本还是标记点，都还在原特征空间中，如果此时假设$x_1$或$l_1$对应的特征值取值范围远远大于$x_2$或$l_2$，那么在上面的式子中$(x_1-l_1)^2$将会远远大于$(x_2-l_2)^2$，后者在计算两个向量的差值的范数的时候可以忽略不计，从而忽略了特征$x_2$的信息

最后要说明的一点是当我们要使用逻辑回归模型或支持向量机时，假设n 代表特征的数量，m 是训练集样本容量，我们应该如何选择使用的算法呢？

当特征数量n 的值比训练样本个数大时，我们通常使用逻辑回归模型或者用不带核函数的SVM（比如线性核函数），因为如果我们有许多特征变量而有相对较小的训练集，线性函数可能会表现的很好，而且实际上我们也没有足够的数据来拟合非常复杂的非线性函数；如果n 比较小，m 大小适中（相比较于特征数n 来说，例如1:10），这时高斯核函数的SVM 会工作的很好；还有一种情况是n 非常小，而m 相比较来说非常大，这个时候高斯核函数的运算速度会很慢，因为通常软件中调用的高斯核函数默认为使用所有训练集样本作为标记点，这样会得到一个m 维的高维空间，在优化目标时计算量会非常大