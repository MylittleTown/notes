### 推荐系统

首先来看下推荐系统在平常的应用场景，假设$n_u$表示用户的数量，下标u 表示具体指哪个用户，$n_m$表示商品的数量，在推荐系统中我们的数据由以下几个组成，值$r(i,j)$代表用户j 是否给商品i 进行了评价，当然，由于用户仅仅评价了一部分商品，有一些商品没有获得该用户的评价，当$r(i,j)=1$时，也就是当用户i 对商品j 进行评分后，我们会得到一个值$y^{(i,j)}$，它表示用户j 对商品i 所给出的评分

因此，推荐系统问题指的是给出$r(i,j)$和$y^{(i,j)}$的数据，然后去查找那些没有被评分的商品，并试图预测这些商品的评分。换句话说，如果我们想开发推荐系统，那我们的工作是设计一个学习算法，一个能自动为我们填补没有评分的商品的缺失值的算法，我们可能会在过程中发现某个用户没有使用过的商品并推荐新的商品给该用户，也可以预测什么是用户会感兴趣的内容

第一种建立推荐系统的方法是基于内容的推荐算法。假设对于每一种商品我们都有一个对应的特征集，特别的，我们假设每一种商品都有n 个特征$\{x_1,x_2,\cdots,x_n\}$，那么每种商品就可以用一个特征向量来表示，即$x^{(i)}=\left[\begin{matrix}x_1^{(1)}\\x_2^{(i)}\\\vdots\\x_n^{(i)}\end{matrix}\right]$，上标$(i)$表示该特征向量表示的商品的编号

现在为了作出预测，我们可以把每个用户的评价预测值看作一个线性回归问题，特别规定对于每一个用户j 我们要学习参数向量$\theta^{(j)}\in R^{n+1}$，这里比特征数量多了1 个截距项$x_0=1$对应的参数$\theta_0$，然后我们要预测用户j 评价商品i 的值，也就是参数向量$\theta$与特征量$x^{(i)}$的内积。总结来说我们这里的操作就是对每一个用户应用了一个不同的线性回归的模型参数来预测他们对某一类型商品的评分

更正式一些可以将上面的过程写成如下：

如果用户j 评价了商品i，我们就设置$r(i,j)=1$，而$y^{(i,j)}$是用户j 对商品i 的评价后（即此时$r(i,j)=1$）的评分值，$\theta^{(k)}$表示每个用户$x^{(k)}$的一个参数向量，而$x^{(k)}$是特定商品的特征向量，对于每一个用户和商品，我们会通过计算$(\theta^{(k)})^Tx^{(k)}$的结果来预测，引入$m^{(j)}$表示用户j 评价了的商品数量

如此一来这就变成了一个基本的线性回归问题，我们可以直接选择一个参数向量$\theta^{(j)}$，而$(\theta^{(j)})^Tx^{(i)}$的预测值会尽可能接近我们在训练集中观察的值。为了学习参数$\theta^{(j)}$，我们需要最小化代价函数（即优化目标），我们把用户j 所评价的所有商品进行求和，写成$\sum_{i:r(i,j)=1}$，那么训练集中关于用户j 对所有商品的评价的代价函数可以写成
$$
\frac{1}{2m^{(j)}}\sum_{i;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i)})^2
$$
同样的，我们也可以加入正则化项，即$\frac{\lambda}{2m^{(j)}}\sum_{k=1}^n(\theta^{(j)}_k)^2$，其中$\theta^{(j)}\in R^{n+1}$而我们通常不会对$\theta^{(j)}_0$进行正则化，即不对偏置单元进行正则化，所以正则化项的求和公式从k = 1 开始

如果我们将上面的代价函数公式最小化，会得到一个好的结果，得到一个相当好的关于参数向量$\theta^{(j)}$的估计值，用来对用户j 的对商品的评价做预测

其实为了将上面代价函数的计算表达式推广到一般情况，我们发现$m^{(j)}$（即用户j 评价过的商品的数量）对于$\theta^{(j)}$的推导过程来说是常数，不会影响优化目标过程的结果，于是上面的代价函数的计算表达式可以改写成
$$
\underset{\theta^{(j)}}{min}\frac{1}{2}\sum_{i;r(i,j)=1}((\theta^{(j)})^Tx^{i}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{k=1}^n(\theta_k^{(j)})^2
$$
当构建推荐系统时，我们不仅是要学习单个用户的参数向量$\theta^{(j)}$，而是要学习所有用户的参数$\{\theta^{(1)},\theta^{(2)},\cdots,\theta^{(n_u)}\}$，所以将上面的优化目标函数进一步改写为如下
$$
J(\theta^{(1)},\cdots,\theta^{(n_u)})=\underset{\theta^{(1)},\cdots,\theta^{(n_u)}}{min}\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(\theta_k^{(j)})^2
$$
相当于是做了一个额外的求和，这里是对所有目标进行求和并且要最小化

为了实现最小化，我们可以尝试用梯度下降更新的方法，更新的计算表达式如下
$$
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\sum_{i;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}（当k = 0 时）\\
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\left(\sum_{i;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda\theta_k^{(j)}\right)（当k \neq 0时）
$$
因为正则项中求和从k = 1 到n，也就是仅对$\theta_k^{(j)},k=1,2,\cdots,n$进行正则化，所以更新的表达式要分为$k = 0$和$k\neq 0$来表示。而第二部分的求和项中的式子实际上就是关于优化目标函数的参数的偏导数，也就是$\frac{\partial}{\partial\theta_k^{(j)}}J(\theta^{(1)},\cdots,\theta^{(n_u)})$，事实上，到了这也会发现之前忽略用户j 评价过的商品数量$m^{j}$这个变量的值能很好的简化梯度下降更新的偏导数推导过程。

这个算法叫做基于内容的推荐算法或基于内容的方法，因为我们假设变量是已有的，即不同商品的各个特征，我们有描述商品内容和性质的特征量，同时我们用了这些描述商品的特征的值来做出预测。但是对于许多商品，我们并没有这样的特征量或者很难获取所有商品的这些特征值，下面我们将介绍一个新的方法，它不是基于内容的并且不去假设我们已经得到这些商品的特征：协同过滤

协同过滤最大的特点在于特征学习，也就是说，这种算法能够自行学习所要使用的特征，下面将这个算法标准化到一般情况

假设我们的用户告诉了我们他们的偏好，也就是用户已经给我们提供了参数向量$\theta^{(1)},\theta^{(2)},\cdots,\theta^{(n_u)}$的值，而我们想要学习商品i 的特征向量$x^{(i)}$，我们就根据所有用户给商品i 提出的评分以及用户j 的喜好对应的$\theta^{(j)}$来计算下面这个优化目标的函数
$$
\underset{x^{(i)}}{min}\frac{1}{2}\sum_{j;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{k=1}^n(x_k^{(i)})^2
$$
我们通过最小化优化目标得到的商品i 的特征向量$x^{(i)}$使得我们预测用户j 对商品i 的评分与我们从用户j 处实际得到的评分值不会相差太远，也就是要使得优化目标函数的第一部分的求和项中差值尽量的小

总结一下就是，这一阶段要做的就是选择商品i 的特征$x^{(i)}$让算法能够根据所有已经评价过商品i 的用户的喜好$\theta^{(j)}$得到一个值来预测会用户如何评价，而这个预测值在平方误差的形式中要尽量接近于用户实际的评分

下面把这个计算式子用于学习出所有商品的所有特征，只要在原式上加上一个求和符号对所有共$n_m$个商品求和，如下
$$
\underset{x^{(1)},\cdots,x^{(n_m)}}{min}\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^n(x_k^{(i)})^2
$$
我们通常用这两个应用于推荐系统中的算法来获取一个

随机的猜取一些$\theta$值，在有了这些随机初始化的$\theta$值以后，就能通过上面提到的根据用户偏好学习每种商品的特征的方法获得$x^{(i)}$，然后在有这些初始的特征之后，我们就能运用第一种方法（即根据每种商品的特征$x^{(i)}$和不同用户j 对不同商品i 的评分$y^{(i,j)}$来预测每个用户的喜好$\theta^{(j)}$）来得到一个更好的对参数$\theta$值的估计，这样我们就有了一系列能更好的估计用户的$\theta$值，通过这些$\theta$值又可以得到更好的特征，以此类推，我们把这个过程不断重复进行，得到更好的$\theta$和$x$，最后这个过程将会收敛到一组合理的商品特征以及一组合理的不同用户的偏好的参数估计，事实证明，这个效果确实很好

最后总结一下，我们通过上述两种方法来构建推荐系统是仅建立在每位用户都对数个商品进行了评价并且每种商品都被数位用户评价过的情况下，这样我们才能够重复上述这个迭代过程来估计出$\theta$和$x$

### 协同过滤算法

我们在这里先总结一下之前涉及到的两种方法的优化目标函数：
$$
\underset{\theta^{(1)},\cdots,\theta^{(n_u)}}{min}\frac{1}{2}\sum_{j=1}^{n_u}\sum_{i;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(\theta_k^{(j)})^2\quad(1)\\
\underset{x^{(1)},\cdots,x^{(n_m)}}{min}\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^n(x_k^{(i)})^2\quad(2)
$$
分别是假如已知每种商品的特征学习得到用户偏好的参数$\theta$，以及假设已知参数$\theta$估计特征x。下面我们将介绍一个新的算法将同时计算出x 和$\theta$，而避免了之前两种方法不断迭代。

将上面两个优化目标函数结合为一个新的优化目标函数，如下：
$$
J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)})=\frac{1}{2}\sum_{(i,j);r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^n(x_k^{(i)})^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(\theta_k^{(j)})^2
$$
这个优化目标函数J 有个有趣的性质，如果假设x 为常数并关于$\theta$优化的话，其实我们就是在计算式(1)，反过来也一样，如果把$\theta$作为常量然后关于x 求J 的最小值的话，那就与式(2) 效果相同，因为如果只关于x 或$\theta$进行最小化运算的话，新的优化目标函数的后面两项会有一项变为常数

我们的优化目标就可以写成：
$$
\underset{x^{(1)},\cdots,x^{(n_m)},\\\theta^{(1)},\cdots,\theta^{(n_u)}}{min}J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)})
$$
综上所述，协同过滤算法的过程如下：

首先我们将会随机初始化x 和$\theta$为小的随机值，接下来通过梯度下降或者其他的高级优化算法把代价函数最小化，梯度下降更新的方法的每步更新的表达式可以写成如下：
$$
x_k^{(i)}:=x_k^{(i)}-\alpha\left(\sum_{j;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})\theta_k^{(j)}+\lambda x_k^{(i)}\right)\\
\theta_k^{(j)}:=\theta_k^{(j)}-\alpha\left(\sum_{i;r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda \theta_k^{(i)}\right)
$$
这两式的第二项就是分别代价函数关于$x_k^{(i)}$和$\theta_k^{(j)}$的偏微分，即$\frac{\partial}{\partial x_k^{(i)}}J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)})$和$\frac{\partial}{\partial \theta_k^{(j)}}J(x^{(1)},\cdots,x^{(n_m)},\theta^{(1)},\cdots,\theta^{(n_u)})$

最后，给定一个用户以及他的偏好$\theta$和一个带有已知特征和特征值x 的商品，我们就可以预测该用户给这类型商品的评分$\theta^Tx$

### 协同过滤算法向量化：低秩矩阵分解

假设我们有$n_m$种商品以及$n_u$个用户，并收集了这些用户对个别商品的评分$y^{(i,j)}$，其中也有用户未作评分的情况，那么，将这些评分按照参数i 和j 形成一个矩阵Y，有
$$
Y=\left[\begin{matrix}y^{(1,1)}\:y^{(1,2)}\:\cdots y^{(1,n_u)}\\
y^{(2,1)}\:y^{(2,2)}\:\cdots y^{(2,n_u)}\\
\vdots\\
y^{(n_m,1)}\:y^{(n_m,2)}\:\cdots y^{(n_m,n_u)}\end{matrix}\right]
$$
该矩阵行来存放同一用户对不同种类商品的评分，按照列存放同一种类商品在不同用户的评分情况

同理用户j 对商品i 的评分预测也由$(\theta^{(j)})^Tx^{(i)}$计算得到，评分结果也可以存储为一个矩阵
$$
\left[\begin{matrix}(\theta^{(1)})^Tx^{(1)}\:(\theta^{(2)})^Tx^{(1)}\:\cdots (\theta^{(n_u)})^Tx^{(1)}\\
(\theta^{(1)})^Tx^{(2)}\:(\theta^{(2)})^Tx^{(2)}\:\cdots (\theta^{(n_u)})^Tx^{(2)}\\
\vdots\\
(\theta^{(1)})^Tx^{(n_m)}\:(\theta^{(2)})^Tx^{(n_m)}\:\cdots (\theta^{(n_u)})^Tx^{(n_m)}\end{matrix}\right]
$$
这就是我们预测评分的矩阵，矩阵元素的标号为$(i,j)$，这也对应了我们预测的用户j 给商品i 的打分的计算公式为$(\theta^{(j)})^Tx^{(i)}$，因此这个矩阵中第一个元素，即第一行第一列的元素，表示的就是用户1 对商品1 的评分预测，第一行第二列的元素表示第二个用户对第一种商品的评分预测，以此类推

我们也可以通过比较简单的向量化的方法来推导这个预测评分矩阵，假设两个矩阵X 和$\Theta$写成如下形式
$$
X=\left[\begin{matrix}(x^{(1)})^T\\(x^{(2)})^T\\\vdots\\(x^{(n_m)})^T\end{matrix}\right]\quad\quad\quad
\Theta=\left[\begin{matrix}(\theta^{(1)})^T\\(\theta^{(2)})^T\\\vdots\\(\theta^{(n_u)})^T\end{matrix}\right]
$$
矩阵X 中存放的是我们提取所有商品的特征$x^{(i)}\in R^n$并逐行写入；矩阵$\Theta$中写入每个用户参数向量。那么预测评分矩阵就可以用向量化的方法来计算，即$X\Theta^T$。

从线性代数的角度来看，预测评分的矩阵具有低秩性，即行和列向量之间的相关性大，低秩矩阵可以用另一种方式来理解

![低秩矩阵通俗解释用图](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E4%B8%89%E5%8D%81%E5%9B%9B%E5%8D%81%E4%BA%94%E7%AB%A0-%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F%E7%A4%BA%E4%BE%8B.png)

可以理解为，额，草原是由很多草组成的，而草是相似的，所以如果全是草，那么这张图所包含的信息量是很少的的，因为可以理解为草是草的复制品。而上图的蒙古包，人，马之类的则可以理解为图片所包含的信息，实际上，相对于只有草的草原图片和有草和蒙古包的草原图片，后者的秩是较高的。也就是说，图片中比较突兀的成分，比如蒙古包，比如人像照片中的红眼亮点，会增加图像矩阵的秩。而现实生活中一张不错的图片的秩其实是比较低的，如果图像的秩比较高，往往是因为图像中的噪声比较严重。比如拍照的时候ISO感光度设置过高造成噪点太过泛滥之类的。所以，额，图像处理的低秩性其实可以拿来去除照片中的噪点，电影中的雨丝也可以通过低秩表达的方式来去除。

（上述解释过于精彩就摘抄下来，附上源址

作者：柒生
链接：https://www.zhihu.com/question/28630628/answer/98955466
来源：知乎）

从数据的角度来分析，矩阵的秩表示数据的冗余程度，秩越低表示数据冗余越大，因为用很少几个基就能表达矩阵内的所有数据。相反，秩越大表示数据冗余性越小。低秩矩阵的每行或每列都可以用其他的行或列线性表示，利用这种冗余，可以对缺失数据进行恢复，也可以对数据进行特征提取。

### 协同过滤算法：均值规范化

我们考虑一个特殊情况，在已知数据集中，某个用户j 对所有商品都没有进行评分，那么在优化目标的函数中影响该用户的参数$\theta^{(j)}$的应该只剩下第三部分的求和项（因为此时$r(k,j)=0,k=1,2,\cdots,n_m$，所以第一部分求和为0，完全无影响）那么，原式可以改写为：
$$
\underset{x^{(1)},\cdots,x^{(n_m)},\\\theta^{(1)},\cdots,\theta^{(n_u)}}{min}\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^n(\theta_k^{(j)})^2
$$
其中n 表示数据集中商品的特征个数，对于这个优化过程不难发现，优化结果应该是$\theta^{(j)}=\left[\begin{matrix}0\\0\\\vdots\\0\end{matrix}\right]$，这样的话如果我们要预测该用户会如何给商品打分，计算$(\theta^{(j)})^Tx^{(i)}$对任意i 值都为0，也就是说我们将预测用户j 给所有商品的评分都是0，给所有商品打分相同这个是没有任何意义的。我们可以用均值规范化的方法来避免出现这种情况

首先我们根据已知数据集构造矩阵Y 并在最后一列给该用户新增一列并用“？”表示当前未评分
$$
Y=\left[\begin{matrix}y^{(1,1)}\:y^{(1,2)}\:\cdots y^{(1,n_u)}\:?\\
y^{(2,1)}\:y^{(2,2)}\:\cdots y^{(2,n_u)}\:?\\
\vdots\\
y^{(n_m,1)}\:y^{(n_m,2)}\:\cdots y^{(n_m,n_u)}\:?\end{matrix}\right]
$$
接下来我们要做的就是计算每种商品所得评分的均值，并将它们存在列向量$\mu$中，即
$$
\mu^{(i)}=\frac{\sum_{j=1}^{n_u}y(i,j)}{n_u}\\
\mu=\left[\begin{matrix}\mu_1\\\mu_2\\\vdots\\\mu_{n_m}\end{matrix}\right]
$$
然后将矩阵Y 中的每行的元素减去对应的均值，也就是用户对每种商品的评分减去该商品在所有用户的评价中的平均分，这个新的矩阵Y' 写成如下
$$
Y'=\left[\begin{matrix}(y^{(1,1)}-\mu_1)\:(y^{(1,2)}-\mu_1)\:\cdots (y^{(1,n_u)}-\mu_1)\:?\\
(y^{(2,1)}-\mu_2)\:(y^{(2,2)}-\mu_2)\:\cdots (y^{(2,n_u)}-\mu_2)\:?\\
\vdots\\
(y^{(n_m,1)}-\mu_{n_m})\:(y^{(n_m,2)}-\mu_{n_m})\:\cdots (y^{(n_m,n_u)}-\mu_{n_m})\:?\end{matrix}\right]
$$
此时矩阵Y' 中每种商品评分都被归一化，其均值都为0，之后我们就可以对评分数据集新矩阵Y' 使用协同过滤算法，用它作为我们的数据集来学习参数$\theta^{(j)}$和商品特征$x^{(i)}$，这样当我们要预测用户j 对商品i 的评分时，首先计算$(\theta^{(j)})^Tx^{(i)}$，这两个向量都是从均值归一化后的新矩阵Y' 中学习得到的参数，因为这个新的数据集已经做过均值归一化，每个元素都减去了相应的均值，所以为了给商品i 预测评分的时候还需要在原式基础上加上均值，所以预测评分的表达式为$(\theta^{(j)})^Tx^{(i)}+\mu_i$，这就是我们预测的评分

通过上面的步骤计算得到的预测评分能避免出现我们预测新增用户给商品评分为0 的情况，因为这时$(\theta^{(j)})^Tx^{(i)}+\mu_i=0+\mu_i=\mu_i$，这个预测结果就有了实际意义，它表示对于新增用户没有给任何商品评分时，也就是我们推荐系统对该用户一无所知，我们将预测每一种商品所获得的平均评分

### 学习海量数据集

接下来我们将讨论对普通梯度下降算法的改进，称之为随机梯度下降法，这将使我们的算法能应用于更大的训练集

之前学习的线性回归模型的假设函数和代价函数的表达式如下：
$$
h_\theta(x)=\sum_{j=0}^n\theta_jx_j\\
J_{train}(\theta)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2
$$
而梯度下降算法中更新的步长的表达式是$\theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$，我们要在梯度下降的内部循环中用该式子反复更新参数$\theta$的值

当我们学习海量数据集时上述方法就会遇到一个问题，当m 值很大时，计算梯度下降法的内循环中更新参数的表达式计算量会变得非常大，因为表达式内的求和项是对m 个样本进行求和。这种梯度下降算法又称为“批量梯度下降”，“批量”这个词指的是我们每次都要考虑所有的训练样本。大的计算量往往需要大的计算资源，比如计算机内存，而如果内存无法同时存储海量数据集进行计算时就需要计算机从硬件存储资源中不断读写，速度往往很慢，所以效率很低

在随机梯度下降算法中，我们用另一种形式来表示代价函数，首先定义损失函数$cost(\theta,(x^{(i)},y^{(i)}))=\frac{1}{2}(h_\theta(x^{(i)})-y^{(i)})^2$，这个损失函数实际上是衡量我们的假设函数在样本$(x^{(i)},y^{(i)})$上的表现，那么总体代价函数就可以写成
$$
J_{train}(\theta)=\frac{1}{m}\sum_{i=1}^mcost(\theta,(x^{(i)},y^{(i)}))
$$
即假设函数在m 个训练样本中的每一个样本$(x^{(i)},y^{(i)})$上的损失函数的平均值

算法思路如下：

第一步是随机打乱所有数据，也就是将所有m 个训练样本重新随机排列，这是标准的数据预处理过程；第二步是在i 从1 到m 循环，也就是遍历所有训练样本，然后进行如下所示的更新
$$
\theta_j:=\theta_j-\alpha(h_\theta(x^{(i)})-y^{(i)})x^{(i)}_j(j=1,\cdots,n)
$$
上式中的第二项实际上是损失函数$cost(\theta,(x^{(i)},y^{(i)}))$分别对参数$\theta^{(i)}_j$求偏导，这个i 从1 到m 的循环实际上就是遍历所有的训练样本，可以看作将每一个样本的代价函数生成后直接去对每个参数$\theta^{(i)}_j$更新，使其对该训练样本拟合的更好一点，直到完成所有的训练集

从第二步的解释就能理解为什么数据预处理部分需要随机排列训练集样本，通过第一步处理保证了我们在遍历训练集时对训练集样本的访问是以随机顺序排列的，这不像之前“批量梯度下降”中每次循环是对整个训练集计算梯度并更新参数

（不管数据是否已经随机排列过或是一开始就按照某种奇怪的顺序排列，通过第一步重新随机排列能让随机梯度下降在收敛时更快一点）

需要注意的是，随机梯度下降算法的第二步实际上可能不止遍历一次训练集样本，第二步循环的次数取决于训练集的大小，通常一次就够了，最多到10次，当训练集容量m 非常大的时候，一次遍历训练集样本就能得到一个非常好的假设

对于随机梯度下降另一个重要的一点是，与批量梯度下降不同，它不需要对全部m 个样本求和来得到梯度更新的表达式的第二部分，而是只需要对单个训练样本求出关于每个参数$\theta^{(i)}_j$的偏导项，相比较而言我们随机梯度下降的算法减少了外层循环的计算量。也就是说，我们不需要对所有的数据进行扫描就能对参数进行修改，使其达到全局最小值

当然，如果从整个算法执行的过程中某一时间点来看，批量梯度下降在每个时间点都保证总体代价函数是在不断优化减小，而由于随机梯度下降的算法每次循环只是让假设函数和某一个样本拟合的更好，所以总体代价函数的变化趋势无法确定，甚至在某一时间点总体代价函数的值增大。用一句话总结就是，舍弃了最优路径从而获得时间复杂度的减少

### Mini-batch 梯度下降

目前为止学习的梯度下降算法中，批量梯度下降算法中每次迭代我们都要用到所有的m 个样本，在随机梯度下降算法中每次迭代我们只需要使用一个样本，而在Mini-batch 梯度下降算法则是介于两者之间，具体来说，这个算法每次迭代会使用b 个样本，这里的b 是一个称为“mini-batch 大小” 的参数，它看起来与批量梯度下降算法相似，只不过在Mini-batch 梯度下降算法中我们会用一个小得多的批量大小，通常会选择b 的值为10，它在应用中的取值范围通常是2 到100，这也是一个常用的范围

Mini-batch 梯度下降算法的思想是，既不一次只用一个样本，也不一次用m 个样本，而是一次使用b 个样本，例如假设b = 10，我们将得到训练集中10个样本记作$(x^{(i)},y^{(i)}),(x^{(i+1)},y^{(i+1)}),\cdots,(x^{(i+9)},y^{(i+9)})$，并用这10 个样本来执行梯度下降算法完成更新，即更新表达式写为：
$$
\theta_j:=\theta_j-\alpha\frac{1}{10}\sum_{k=1}^{i+9}(h_\theta(x^{(k)})-y^{(k)})x^{(k)}_j
$$
线性速率乘以$\frac{1}{10}$。在上面这个例子中是对10 个样本进行梯度求和的，这个10 就是Mini-batch 大小的值，也是由我们选择的参数b 决定，更新一次结束后我们将增大i 的值使i = 10，然后再使用后10个样本进入下一次循环像这样进行下去

之前我们提到随机梯度下降算法在执行的过程中某一时间点的总体代价函数的值可能没有减小反而增加，因为它是拟合每个样本，这种情况我们也称为寻址偏移，而Mini-batch 梯度下降算法因为考虑了b 个样本，所以容错率会高

三种梯度下降算法总结一下就是，传统GD 运算慢，收敛快，SGD 运算快，收敛慢，Mini-batch 梯度下降算法性能居中。当然，关于运算慢是基于计算资源和每次循环需要消耗的计算资源决定的，通过使用合适的向量化方式计算每次更新的表达式的值，我们可以使用好的数值代数库对b 个样本并行进行梯度计算，例如GPU矩阵运算可以完成并行运算，这个时候它的效果也许甚至比随机梯度下降算法中每次循环只计算一个样本好得多

### 随机梯度下降算法的收敛问题

这里我们将讨论在运行算法时，我们如何确保调试过程已经完成，并且已收敛到合适的位置。还有一件很重要的事就是我们怎么样调整随机梯度下降过程中学习速率$\alpha$的值。

在之前的批量梯度下降算法中，确保梯度下降已经收敛的一个标准方法是根据代价函数的曲线图像，我们要确保这个代价函数在每一次迭代中都是下降的，当训练集比较小的时候，我们很容易迅速的计算出代价函数中的求和项，但是当训练集非常大的时候，总是暂停算法去检查批量梯度下降算法的代价函数是否收敛，因为这样每次要遍历整个训练集，所以计算量很大

在随机梯度下降算法中，当算法遍历样本的循环执行到样本$(x^{(i)},y^{(i)})$，在更新参数$\theta$之前，我们会先计算出这个样本对应的损失函数cost 函数的值，也就是说，当随机梯度下降算法对训练集进行扫描时，在我们使用某个样本$(x^{(i)},y^{(i)})$来更新$\theta$之前，我们需要计算出这个训练样本假设的表现有多好，即$h_\theta(x^{(i)})$与标签$y^{(i)}$差值的平方的值，这个值代表当前假设在该样本上的表现，最后，为了检查随机梯度下降是否收敛，每1000 次迭代，我们就求出这1000 个样本的对应的损失函数的值的均值与上一批1000 个训练样本的均值比较判断随机梯度下降是否收敛（这个变化过程也可以通过图像表示）

事实上，因为是对小部分样本求均值，这样每1000 组样本求取损失函数的平均值画出的图像看起来会有很多噪声，反复震荡，可能不是每一步迭代都在下降，然后在某一点开始图像开始变得平缓，通过这幅图像我们可以判断学习算法已经收敛了，如下图

![随机梯度下降代价函数的收敛图像](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%85%AD%E5%8D%81%E4%B8%83%E5%8D%81%E5%85%AB%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E7%9A%84%E6%94%B6%E6%95%9B%E5%9B%BE%E5%83%8F.png)

通过图像，我们可以发现，在选择较小的学习速率$\alpha$时，算法的学习变得更慢了，所以代价函数下降也变缓了，但使用更小的学习速率最后可能会让算法收敛到一个更好的结果（当然，这种差别可以忽略），对比下图的红色曲线

![随机梯度下降代价函数关于学习速率的收敛曲线对比](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%85%AD%E5%8D%81%E4%B8%83%E5%8D%81%E5%85%AB%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%85%B3%E4%BA%8E%E5%AD%A6%E4%B9%A0%E9%80%9F%E7%8E%87%E7%9A%84%E6%94%B6%E6%95%9B%E6%9B%B2%E7%BA%BF%E5%AF%B9%E6%AF%94.png)

当我们运行随机梯度下降算法时每5000 个样本做一次迭代，绘制出来的损失函数的均值的曲线就会变得更加平滑，当然，它的缺点就是每隔5000 个样本才能得到一个数据点，因此我们所得到的关于算法表现有多好的反馈就显得有一些延迟，因为图中每一个数据点是从5000 个样本中得到的，而不是之前的每1000 个样本求一次均值，图像显示如下图

![随机梯度下降代价函数关于每组样本容量的收敛曲线对比](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%85%AD%E5%8D%81%E4%B8%83%E5%8D%81%E5%85%AB%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%85%B3%E4%BA%8E%E6%AF%8F%E7%BB%84%E6%A0%B7%E6%9C%AC%E5%AE%B9%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B%E6%9B%B2%E7%BA%BF%E5%AF%B9%E6%AF%94.png)

当我们求均值的样本数量太少时，绘制出的图像包含了太多的噪声，导致无法看出整体实际上趋向于减小的，如果选用更大的训练集样本数量为一组求均值，有可能可以得到一组新的曲线，能看出实际上代价函数是在下降的，如红色线，这两种情况如下图所示

![随机梯度下降代价函数的特殊收敛曲线分析](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%85%AD%E5%8D%81%E4%B8%83%E5%8D%81%E5%85%AB%E7%AB%A0-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E7%9A%84%E7%89%B9%E6%AE%8A%E6%94%B6%E6%95%9B%E6%9B%B2%E7%BA%BF%E5%88%86%E6%9E%90.png)

也有可能发现曲线平坦，也就是说即使对更多的样本进行求均值，代价函数基本没有变化，那就代表很明显，也很不幸，算法不知道出于何种原因没有进行学习，那么这时就需要调整学习速率或者调整特征或调整算法的其他东西

最后，我们也可能会遇到曲线看起来是在上升的，这种情况就是算法发散的信号，这时我们要做的就是用一个更小的学习速率$\alpha$

下面我们来介绍如何更好更合适的使用学习速率$\alpha$。

在大多数梯度下降算法的典型应用中，学习速率$\alpha$一般是一个不变的常数，因此我们在运行梯度下降算法时，算法会从某个点开始曲折的达到最小值，但它不会完全收敛，而是在最小值附近一直徘徊，因此我们最终得到的参数只是一个全局最小值的接近值，而不是真正的全局最小值。如果想让梯度下降更好的收敛到全局最小值，我们可以让学习速率$\alpha$的值随时间变化逐渐减小，所以一种典型的方法就是设置$\alpha$ 的表达式为
$$
\alpha=\frac{const1}{iterationNumber+const2}
$$
其中$iterationNumber$ 表示迭代次数，指的是我们运行梯度下降算法过程中的迭代次数，在随机梯度下降算法中其实就是我们已经计算过的训练样本的数量，而常数1 和常数2 是算法的两个额外的参数，同样需要选择合适的值才能得到较好的表现，最后得出的图像中，算法还是会在最小值附近震荡，但它会更加接近最小值，因为这时我们通过$\alpha$的表达式减小了学习速率，那么这个震荡也会越来越小，直到收敛到非常靠近全局最小的地方

### 在线学习

如果我们有一个不断进入网站的用户流所产生的连续的数据流，就可以使用在线学习机制从数据流中学习用户的偏好，然后使用这些信息来优化关于网站的决策

使用在线学习机制需要我们网站一直在线，在某个时间点用户的行为特征以及我们网站要记录的标签值会存储为数据对作为假设函数的输入，我们会利用刚得到的数据对$(x,y)$更新参数$\theta$，例如使用随机梯度下降的更新表达式$\theta_j:=\theta_j-\alpha(h_\theta(x)-y)x_j(j=0,\cdots,n)$，不难发现，在线学习机制中我们丢弃了固定的数据集这一概念，取而代之的是我们获取一个样本并利用这个样本以某种算法模型学习，然后我们丢弃这个样本不会再次使用它，也就是说一次只处理一个样本，从样本中学习在丢弃它，这也就是为什么我们会放弃使用i 作索引的固定数据集的表示方法$(x^{(i)},y^{(i)})$

这种在线学习算法有一个很有趣的性质，它可以适应变化的用户偏好，能做得到这一点是因为如果我们的用户群变化了，那么参数$\theta$的变化与更新会逐渐调试到最新的用户群所体现出来的特点x。这也是在线学习的一个优点，如果我们有一个变化的用户群或者我们在尝试预测的事情在缓慢变化，例如用户的喜好在缓慢变化，在线学习算法可以慢慢的调试我们所学习到的假设，将其调节更新到最新的用户行为

当然，我们也可以很简单的将在线学习问题转化为固定数据集的一般的机器学习问题，只需要设置每隔一段时间将该网站的所有样本存储为一个固定大小的数据集并作为训练样本学习获取参数$\theta$即可，但是对于拥有非常大量数据流的网站或公司来说，这种做法没有必要

### 减少映射与数据并行

很多机器学习问题过于庞大以至于不能单机运行，下面将介绍一种可以应用在大规模机器学习上的方法叫做MapReduce

假设我们想要拟合一个线性回归模型或者逻辑回归模型亦或是其他的机器学习模型，这里以批量梯度下降算法为例，批量梯度下降算法的学习规则写作$\theta_j:=\theta_j-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$，然后假设我们有数据集存储数据对$(x^{(i)},y^{(i)})$，根据MapReduce 的思想，我们把训练集分割成不同的子集，子集的数量由我们已有的并行机器的数量决定，例如如果我们将把这些数据分别运行在4台机器上，那么我们就需要将原数据集分割成4份，对于每份子集，每台机器需要做的就是用这份子集的训练样本计算上面提到的更新参数$\theta$的表达式，同理将其余的子集分配给其他机器，这样就会获得多个临时变量，上述过程的表达式如下
$$
temp_j^{(1)}=\sum_{i=1}^{\frac{m}{4}}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\
temp_j^{(2)}=\sum_{i=1+\frac{m}{4}}^{\frac{m}{4}*2}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\
temp_j^{(3)}=\sum_{i=\frac{m}{4}*2+1}^{\frac{m}{4}*3}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\
temp_j^{(4)}=\sum_{i=\frac{m}{4}*3+1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\
$$
其中临时变量$temp_j^{(i)}$的上标表示对应的子集序号，可以看出，每台机器只需要对$\frac{m}{4}$个样本做求和计算，这使得它们的运算速度提高到原来的四倍，最后，完成这些计算后，我们将这些临时变量重新放在一起，也就是将这些变量发送给一个中心服务器，中心服务器会整合这些结果，它将更新参数$\theta_j$，更新后的参数$\theta_j$的计算表达式为$\theta_j:=\theta_j-\alpha\frac{1}{m}(temp_j^{(1)}+temp_j^{(2)}+temp_j^{(3)}+temp_j^{(4)})(j=0,\cdots,n)$，不难看出，采用分割后的子集完成更新参数$\theta_j$的表达式和原先整体更新$\theta_j$的表达式等效，结果相同

这里要注意的是，虽然结构上和Mini-batch 梯度下降算法相似，但是本质上不同，参数的含义和作用是不一样的，后者分批遍历训练集样本对参数$\theta_j$更新了$\frac{m}{b}$次，而MapReduce 思想的处理是遍历训练集样本实际只对参数更新了一次

如果我们想把MapReduce 应用在某种学习算法上，通过多台机器并行计算来实现加速，需要思考的一个关键问题就是该学习算法是否可以表示成对训练集的一种求和。实际上很多学习算法都可以表示成对训练集的求和，而在大数据集上运行所消耗的计算量就在于需要对非常大的训练集进行求和，所以只要学习算法可以表示为对训练集求和或者学习算法的主要工作可以表示成对训练集的求和，那么就可以用MapReduce 将该学习算法的使用范围扩大到非常非常大的数据集

MapReduce 思想除了应用在多台机器上，也可以用于单台机器的多核心多CPU，这种情况下需要考虑内存是否够用，因为多核心要共享内存，但是相较于前者应用在多台机器上进行并行计算它具有较小的网络延迟。目前存在一些线性代数库能自动将向量化的数据集分作多份利用机器多核并行计算。

### 获取大量数据和人工数据合成

一个最可靠的得到高性能机器学习系统的方法是使用一个低偏差机器学习算法并且使用庞大的训练集去训练它。实际上，机器学习中有一个很棒的概念叫做“人工数据合成”，它并不适用于所有问题，并且将其运用于特定问题时经常需要思考改进并且深入了解它，但是假如这个想法适用于某一个机器学习问题，有时它能为学习算法轻松得到大规模的训练集。人工数据合成主要有两种形式，第一种是自己创造数据，即从零开始创造新数据，第二种是我们已经有小的标签训练集，然后以某种方式扩充训练集，也就是将较小的训练集转化为一个较大的训练集

具体来说，对于第一种方法创造训练集样本，通常考虑样本的特征属性，假设对于某个样本i 有$\{x_1^{(i)},x_2^{(i)},\cdots,x_n^{(i)}\}$，我们要做的就是将其他样本的特征与该样本的特征重新组合，形成新的样本，例如新的样本k 我们可以将它的特征向量表示为$\{x_1^{(i+1)},x_2^{(k)},\cdots,x_n^{(i+k)}\}$，其中样本(i+1)，样本k 和样本(i+k) 是已有的样本；第二种方法，常见的扩充有对特征量的代数变换，例如倍数，指数和幂，有一种扩充方法称为添加失真，在语音识别中，引入额外的语音失真到数据集中，我们可以加入不同的背景音，在引入失真合成数据时，引入的失真应该具有代表性，这些噪声或者扭曲是有可能出现在测试集中的，否则增加没有意义的失真到数据中并没有多大帮助

最后，关于通过人工数据合成来生成大量数据还有几点要注意。

在生成人工训练样本之前，通常最好先确保我们的分类器偏差较低，这样的话，更多的训练数据才会真正的起作用。标准的做法是绘制一个学习曲线来确保我们目前的分类器是低偏差高方差的。如果分类器的偏差太高，那么可以尝试持续增加分类器的特征数量或者增加神经网络隐藏单元的数量直到偏差值降低，然后再花精力到生成大量的人工训练集上

在研究机器学习问题时，要搞清楚获得当前拥有的数据的10倍的数据量需要花费多少努力。通常假如我们能得到当前数据的10 倍的数据量，那么就能使我们的算法运行的更好，所以如果比较容易获得更多数据，尽量去获取，比如人工数据合成或者自己收集数据然后标记它，还有众包数据标记

### 上限分析

上限分析在我们设计某个机器学习系统工作流时能提供一个很有价值的信号来指导我们的工作流中的哪一部分最值得花时间去研究

首先我们来举个工作流的例子，照片光学字符识别，简称照片OCR，对于这个机器学习的应用，我们设计工作流如下

![机器学习问题流水线示例](https://raw.githubusercontent.com/MylittleTown/notes/master/MachineLearning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E8%AF%BE%E7%A8%8B-%E5%90%B4%E6%81%A9%E8%BE%BE/Related_images/%E7%AC%AC%E5%8D%81%E5%85%AD%E5%8D%81%E4%B8%83%E5%8D%81%E5%85%AB%E7%AB%A0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%B5%81%E6%B0%B4%E7%BA%BF%E7%A4%BA%E4%BE%8B.png)

第一步我们获取一幅图像，然后把它传给文字检测系统，识别出文字区域之后，第三步我们将文本区域中的单个字符分割出来，最后我们对这些单个字母进行识别。

在很多复杂的机器学习系统中，这种流水线形式非常普遍，在流水线中会有多个不同的模块，比如在上面的例子中我们有文字检测，字符分割以及字母识别模块，每一个模块都是一个机器学习组件，可能有时候它不是一个机器学习组件，但是它有一系列连接在一起的模块并在一系列数据上执行，最终得出希望的结果

如果我们要设计一个机器学习系统，我们最重要的决定之一是要怎么样设计流水线的各个模块，如何将某个机器学习的问题分成一系列不同的模块，以及设计每一个模块，这通常会影响到算法最终的表现

下面来介绍上限分析的工作：

参照上面照片OCR 的例子设计的流水线，问题是我们应该怎么样分配资源，哪个模块最值得我们投入精力去做，投入时间去改善效果。跟其他机器学习系统的开发过程一样，为了决定如何开发这个系统，一个有效的方法是对学习系统使用一个数值评价度量。对于照片OCR 应用的流水线系统，假如我们用字符准确度作为这个度量，给定一个测试样本图像，我们会得到一个有关对测试图像中的文本识别正确的比例的数值，不管选择什么评价度量，我们都会得到整个系统目前的准确率$Acc_1$。

首先我们关注这个机器学习工作流中的第一个模块，文本检测，而我们要做的就是对于每一个测试样本都给它提供一个正确的文本检测结果，换句话说，我们要遍历每个测试集样本然后人为的告诉算法每一个测试样本中文本的位置，这个时候我们这个机器学习系统在测试样本集上的准确率是100%的，然后以这些文本的位置为该模块的输出，输入到工作流的下一模块中去，我们要做的就是继续运行完接下来的几个模块，也就是字符分割和字符识别，然后使用跟之前一样的评价度量指标来测量整个系统总的准确率$Acc_2$

接着进入工作流的下一个阶段，字符分割，的分析工作，同前面一样，还是去找出我们的测试集并人为完成分割，将人为分割的结果作为该模块的输出传给下一阶段，现在我们不仅用准确的文本检测结果，还同时用标准的字符分割结果，还是遍历测试样本人工的把文本准确的标记成单个的字符，继续完成后续流水线的阶段后用相同的评价度量指标获得整个系统的准确率$Acc_3$

最后，我们执行最后一个模块，字符识别，同样也是人工给出这一模块的正确标签，当然，这样做以后，整个系统的准确率为100%（根据我们对整个系统的评价度量指标的定义）

进行上限分析后我们知道如果对每一个模块进行改善它们各自的上升空间是多大。如果我们有完美的文本检测模块（第一模块），那么整个系统的准确率将从$Acc_1$上升到$Acc_2$，效果增益可以表示为$Acc_2-Acc_1$，这就意味着如果在现有系统的基础上花费时间和精力改善文本检测模块的效果，可以提高系统性能约$(Acc_2-Acc_1)$，同理，如果使用完美的字符分割模块性能提高的增益可以用$(Acc_3-Acc_2)$表示，我们可以用计算比较出来的效果增益来判断改善哪个模块对系统整体提升更有帮助

通过这种分析，我们可以知道提升每个模块的潜在效果如何，或者说如果一个模块近乎完美时，系统性能能增益多少，这就像是给系统表现加上了一个提升的上限值