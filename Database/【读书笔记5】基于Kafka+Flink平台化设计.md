*（本文由网易云音乐实时计算平台研发工程师岳猛分享，主要介绍Flink + Kafka 在网易云音乐的应用实战）*

### 背景介绍

1. 流平台通用框架

   目前流平台通用的架构一般来说包括消息队列，计算引擎和存储三部分，通用架构如下图所示。客户端或者web 的log 日志会被采集到消息队列；计算引擎实时计算消息队列的数据；实时计算结果以Append 或者Update 的形式存放到实时存储系统中去。

   目前，我们常用的消息队列是Kafka，计算引擎一开始采用的是Spark Streaming，随着Flink 在流计算引擎的优势越来越明显，我们最终确定了Flink 作为网易云音乐实时计算平台的统一的实时计算引擎。

   ![image-20201201094313951](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201201094313951.png)

   流数据（事件流，数据流）：流数据可以看成是一组组离散事件集合体，由成千上万个数据源，源源不断的持续生成，生成的数据流以log （非传统意义上的系统日志）方式传送。例如我们金融行业中，用户对哪款基金进行了查看，明细点击了几次，现货期货的下单事件，网购支付事件等。

   流计算，即是面向流数据的计算，针对于流计算系统而言，上游的流数据是实时的，且持续的，例如某视频网站的视频点播事件，24小时都在发生，点播事件是离散且无固定规律的，点播事件构成的流数据，将按照其发生的顺序发送至流系统被计算，只要网站不停运，点播事件流将绵延不绝的流向流系统，而流系统，也将根据这些事件流信息进行计算，形成分类推荐，以及对各个视频进行热度统计等。

   结合上述流计算的概念，流计算引擎需具备三大特点：

   1. 可接受实时，连续的数据流导入

      流计算引擎的上游数据流的特点即是实时，持续，所有流计算引擎系统首先需要具有高可用特性，具有永久提高计算的能力。

   2. 强大的计算能力

      一旦有流数据进入计算引擎，计算引擎则立刻发起计算，并将结果输出至下游，因此，流计算背后的计算模式为“事件驱动”，正如上述所说，数据的价值随着时间流逝而逐渐降低，所以，流计算引擎需要具有高效的计算能力，快速的将数据流的计算结果输出至下游，**并当面对数据流突如其来的小高峰时，同样可快速的生成计算结果**。

   3. 实时且多数据存储端接入

      通常，不同类型的流数据计算结果，需要落地到不同的存储端供后续业务消费，甚至不落地到存储，直接打到页面进行实时输出展示，因此，流计算引擎需可接入多种数据存储端，可能是缓存，数据库，亦或是文件服务存储，消息队列，数据中心等（例如SOFA流计算平台提供封装了的SDK包，对计算拓扑，以及重复使用的组件，如kafka接入，内部log 服务接入，hbase输出，消息队列输出等都进行了抽象封装），并且在此过程中，数据流计算结果的输出，也应该像数据流的输入那样，实时，持续的进行。

   批量计算：指的是收集数据 - 存入DB - 取出分析（先将数据存进去，再处理）

   两者的区别：

   - 与批量计算累计数据不同，流式计算将大数据平摊到各个结点上，连续进行小批量的传输，流动，计算后抛弃
   - 批量计算维护一张表，对表进行各种逻辑操作，流式计算相反，须先定义好计算逻辑，提交到流式计算系统，计算逻辑在整个运行期间不可更改
   - 计算结果上，批量计算是对全部数据计算后传输结果，流式计算是每次小批量计算后，结果可以立刻传输，做到实时

2. 为什么选择Kafka？

   Kafka 是一个比较早的消息队列，但是它是一个非常稳定的消息队列，有着众多的用户群体，网易也是其中之一。考虑Kafka 作为消息中间件的主要原因如下：

   - 高吞吐，低延迟：每秒几十万QPS 且毫秒级延迟
   - 高并发：支持数千客户端同时读写
   - 容错性：支持数据备份，允许节点丢失
   - 可扩展性：支持热扩展，不会影响当前线上业务

3. 为什么选择Flink？

   Apache Flink 是近年来越来越流行的一款开源大数据流式计算引擎，它同时支持了批处理和流处理，考虑Flink 作为流式计算引擎的主要因素是：

   - 高吞吐，低延迟，高性能
   - 高度灵活的流式窗口
   - 状态计算的Exactly-once 语义
   - 轻量级的容错机制
   - 支持EventTime 及乱序事件
   - 流批统一引擎

4. Kafka + Flink 流计算体系

   基于Kafka 和Flink 的在消息中间件以及流式计算方面的耀眼表现，产生了围绕Kafka 及Flink 为基础的流计算平台体系，如下图所示：基于APP，web等方式将实时产生的日志采集到Kafka，然后交由Flink 来进行常见的ETL，全局聚合以及Window 聚合等实时计算。

   ![image-20201201113010511](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201201113010511.png)

5. 网易云音乐使用Kafka 的现状

   目前有10+个Kafka 集群，各个集群的主要任务不同，有些作为业务集群，有些作为镜像集群，有些作为计算集群等。当前Kafka 集群的总节点数达到200+，单Kafka 峰值QPS 400W+。目前，网易云音乐基于Kafka + Flink 的实时任务达到了500+。

### Flink + Kafka 平台化设计

基于以上情况，网易云音乐想要对Kafka + Flink 做一个平台化开发，减少用户的开发成本和运维成本。在2018年就开始基于Flink 做一个实时计算平台，今年进行了重构。

基于Flink 1.0 版本做了一个Magina 版本的重构，在API 层提供了Magina SQL 和 Magina SDK 贯穿DataStream 和SQL 操作；然后通过自定义Magina SQL Parser 把这些SQL 转换成Logical Plan（执行计划），再将Logical Plan 转化为物理执行代码，在这过程中会去通过catalog 连接元数据管理中心去获取一些元数据的信息。在使用Kafka 的过程中，会将Kafka 元数据信息登记到元数据中心，对实时数据的访问都是以流表的形式。在Magina 中网易云音乐实时计算平台对Kafka 的使用主要做了三部分工作：

- 集群catalog 化
- Topic 流表化（这里的Topic 大概就是Kafka 在使用者端定义的topic ）
- Message Schema 化

用户可以在元数据管理中心登记不同的表信息或者catalog 信息等，也可以在DB 中创建和维护Kafka 的表，用户在使用的过程只需要根据个人需求使用相应的表即可。

### Kafka 在实时数据仓库中的应用

1. 在解决问题中发展

   在平台初期，最开始用于实时计算的只有两个集群，且有一个采集集群，单Topic 数据量非常大；不同的实时任务都会消费同一个大数据量的Topic，Kafka 集群IO 压力异常大；因此，在使用的过程中发现Kafka 的压力异常大，经常出现延迟，I/O 飙升。

   一开始想到把大的Topic 进行实时分发来解决上面的问题，基于Flink 1.5设计了如下图所示的数据分发的程序，也就是实时数仓的雏形。基于这种大的Topic 分发成小的Topic 的方法，大大减轻了集群的压力，提升了性能，另外，最初使用的是静态的分发规则，后期需要添加规则的时候要进行任务的重启，对业务影响比较大，之后考虑了使用动态规则来完成数据分发的任务。

   ![image-20201202144216719](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201202144216719.png)

   解决了平台初期遇到的问题之后，在平台进阶过程中Kafka 又面临新的问题：

   - 虽然进行了集群的扩展，但是任务量也在增加，Kafka 集群压力仍然不断上升
   - 集群压力上升有时候出现I/O 相关问题，消费任务之间容易互相影响
   - 用户消费不同的Topic 过程没有中间数据的落地，容易造成重复消费*（Q: 是缺少缓存区吗？）*
   - 任务迁移Kafka 困难

   针对以上问题，进行了如下图所示的Kafka 集群隔离和数据分层处理。其过程简单来说，将集群分成DS 集群，日志采集集群，分发集群，数据通过分发服务分发到Flink 进行处理，然后数据清洗进入到DW 集群，同时在DW 写的过程中会同步到镜像集群，在这个过程中也会利用Flink 进行实时计算的统计和拼接，并将生成的ADS 数据写入在线ADS 集群和统计ADS 集群。通过上面的过程，确保了对实时计算要求比较高的任务不会受到统计报表的影响（通过镜像服务将计算和DW 写的过程分开，做到同步）。

   ![image-20201202160314467](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201202160314467.png)

   通过上面的过程确保了对实时计算要求比较高的任务不会受到统计报表的影响。但是分发了不同的集群以后就不可避免的面临新的问题：

   - 如何感知Kafka 集群状态？
   - 如何快速分析Job 消费异常？
   - （Q: 采用镜像服务，如何保证一致性？如果发现不一致又将如何及时有效的处理？）

   针对上面两个问题，设计了一个Kafka 监控系统，其监控分为如下两个维度，这样在出现异常的时候就可以进行具体判断出现问题的详细情况：

   - 集群概况的监控：可以看到不同集群对应的Topic 数量以及运行任务数量，以及每个Topic 消费任务数据量，数据流入量，流入总量和平均每条数据大小；
   - 指标监控：可以看到Flink 任务以及对应的Topic，GroupID，所属集群，启动时间，输入带宽，InTPS，OutTPS，**消费延迟**（延迟问题下面会有介绍）以及Lag 情况。

### 问题 & 改进

在具体的应用过程中，也遇到很多问题，最主要的两个问题是：

- 多Sink 下Kafka Source 重复消费问题；
- 同交换机流量激增消费计算延迟问题。

1. 多Sink 下Kafka Source 重复消费问题

   Magina 平台上支持多Sink，也就是说在操作过程中可以将中间的任意结果插入到不同的存储中*（Q: 为什么要插入到不同的存储中？避免中间结果数据量过大吗，对于存储资源的问题目前来说已经不是问题了才对；如果这里的不同的存储指的是集群下存储在多台机器的内存中，那为什么要分开存储呢，中间结果已经是流计算分布式系统下的分发产物，还有继续分发的必要吗？）*。这个过程中就会出现一个问题，比如同一个中间结果，我们把不同的部分插入到不同的存储中，那么就会有多条DAG，虽然都是临时结果，但是也会造成Kafka Source 的重复消费，对性能和资源造成极大的浪费。

   于是思考是否可以避免临时中间结果的多次消费。在1.9版本之前，进行了StreamGraph 的重建，将三个DataSource 的DAG 进行了合并；在1.9版本，Magina 自己也提供了一个查询和Source 合并的优化；但是发现如果是在同一个data update 中有对同一个表的多个Source 的引用，它自己会合并，但是如果不是在同一个data update 中，是不会立即合并的，于是在1.9版本之后对modify Operations 做了一个buffer 来解决这个问题。
   
2. 同交换机流量激增消费计算延迟问题

   也可能不仅仅是同交换机，同机房的情况也可能。在同一个交换机下平台部署了很多机器，一部分机器部署了Kafka 集群，还有一部分部署了Hadoop 集群。在Hadoop 上面可能会进行Spark，Hive 的离线计算以及Flink 的实时计算，Flink 也会消费Kafka 进行实时计算。在运行的过程中我们会发现某一个任务会出现整体延迟的情况，排查过后没有发现其他的异常，除了交换机在某一个时间点的浏览激增，进一步排查发现是离线计算的浏览激增，又因为同一个交换机的带宽限制，影响了Flink 的实时计算（带宽占用堵塞）。
   
   为解决这个问题，就考虑要避免离线集群和实时集群的相互影响，去做交换机部署或者机器部署的优化，比如离线集群单独使用一个交换机，Kafka 和Flink 集群也单独使用一个交换机，从硬件层面保证两者之间不会相互影响。
   
   *（Q: 如果带宽问题会造成暂时的交换机堵塞，那么对于数据链路层之上的网络层，传输层是否需要注意？猜想：也许离线和实时集群必须在同一网络下，无法避免）*
### Q & A

Q1: Kafka 在实时数仓中的数据可靠吗？

A1: 这个问题的答案更多取决于对数据准确性的定义，不同的标准可能得到不同的答案。自己首先要定义数据在什么情况下是可靠的，另外要在处理过程中有一个很好的容错机制。

Q2: 在处理Kafka 的过程中，异常的数据怎么处理，有检测机制吗？

A2: 在运行的过程中平台有一个分发服务，在分发的过程中会根据一定的规则来检测哪些数据是异常的，哪些是正常的，然后将异常的数据单独分发到一个异常的Topic 中去做查询等，后期用户在使用的过程中可以根据相关指标和关键词到异常的Topic 中去查看这些数据。

   


