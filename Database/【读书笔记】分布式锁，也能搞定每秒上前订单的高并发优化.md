### 库存超卖现象是怎么产生的？

超卖 -- 超买的相对称，是指就基本面因素而言，资产价格已跌至不合理的水平，通常发生在价格短期内急跌之后。超卖意味着价格很容易出现向上调整。

先看看如果不用分布式锁，所谓的电商库存超卖是什么意思？如下图：

![image-20201204100938749](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201204100938749.png)

这个图，其实很清晰了，假设订单系统部署两台机器上，不同的用户都要同时买10台iphone，分别发了一个请求给订单系统。接着每个订单系统实例都去数据库里查了一下，当前iphone 库存是12台。

由于当前库存查询返回结果12台大于要买的10台的数量，每个订单系统实例都发送SQL 到数据库里“下单”，然后扣减了10个库存，其中一个将库存从12台扣减为2台，另外一个将库存从2台扣减为-8台。（听起来像不可重复读）

### 用分布式锁如何解决库存超卖问题？

先来介绍一下分布式锁的原理：

同一个锁key，同一时间只能有一个客户端拿到锁，其他客户端会陷入无限等待来尝试获取那个锁，只有获取到锁的客户端才能执行下面的业务逻辑。

![image-20201204101757120](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201204101757120.png)

这里lock 就是分布式锁，在第7行到第13行代码表示的业务操作中，其他客户端是不可以做相同操作的。（Q: 那如果这里我们在数据库的表中增加排他锁呢？）

五种事务隔离级别：

- TRANSACTION_NONE：不使用事务
- TRANSACTION_READ_UNCOMMITTED：允许脏读
- TRANSACTION_READ_COMMITTED：防止脏读，最常用的隔离级别，并且是大多数数据库的默认隔离级别
- TRANSACTION_REPEATABLE_READ：可以防止脏读和不可重复读
- TRANSACTION_SERIALIZABLE：可以防止脏读，不可重复读和幻读

以上的五个事务隔离级别都是在Connection 接口中定义的静态常量，即在应用程序构建与数据库之间的连接时可以手动设置，调用方法setTransactionIsolation(int level)可以设置事务隔离级别，如con.setTransactionIsolation(Connection.REPEATABLE_READ)；

脏读：修改时加排他锁，直到事务提交后才释放，读取时加共享锁，读取完释放事务1读取数据时加上共享锁后（这样在事务1读取数据的过程中，其他事务就不会修改该数据），不允许任何事务操作该数据，只能读取，之后事务1 如果有操作，那么会转换为排他锁，其他事务更无权参与进来读写，从而防止了脏读问题。

但是当事务1 读取数据过程中，有可能其他事务也读取了该数据，读取完毕后共享锁释放，此时事务1 修改数据，修改完毕提交事务，其他事务再次读取数据时候发现数据不一致，就会出现不可重复读问题，所以这样不可避免不可重复读问题。

不可重复读：读取数据时加共享锁，写数据时加排他锁，都是**事务提交后**才释放锁。读取时候不允许其他事务修改该数据，不管数据在事务过程中读取多少次，数据都是一致的，避免了不可重复读问题。

下面解释为什么分布式锁可以避免库存超卖：

![image-20201204110757921](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201204110757921.png)

（在redis 服务器加锁，redis 用于对每个请求分配一个key ），从上图可以看到，只有一个订单系统实例可以成功加分布式锁，然后只有这一个实例可以查库存，判断库存是否充足，下单扣减库存，接着释放锁。

释放锁之后，另外一个订单系统实例才能加锁，接着查库存，发现库存只有2台了，库存不足，无法购买，下单失败。不会将库存扣减为-8的。

### 分布式锁的方案在高并发场景下

现在我们来看看，分布式锁的方案在高并发场景下有什么问题？分布式锁一旦加了之后，对同一个商品的下单请求，会导致所有客户端都必须对同一个而商品的库存锁key 进行加锁。

比如，对iphone 这个商品的下单，都必须对“iphone_lock” 这个锁key 来加锁。这样会导致对同一个商品的下单请求必须串行化，一个接一个的处理。

假设加锁之后，释放锁之前，查库存，创建订单，扣减库存，这个过程性能很高，全过程设为20毫秒。那么1秒是1000毫秒，只能容纳50个对这个商品的请求一次串行完成处理。比如一秒钟来50个请求，都是对iphone 下单的，那么每个请求处理20毫秒，一个一个来，最后1000毫秒正好处理完50个请求。如下图：

![image-20201204111851159](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201204111851159.png)

也就是说，分布式锁在高并发场景下的缺陷就是同一个商品多用户同时下单的时候，会基于分布式锁串行化处理，导致无法同时处理同一个商品的大量下单的请求。

### 如何对分布式锁进行高并发优化？

其实说出来很简单，相信很多人看过java 里的ConcurrentHashMap 的源码和底层管理，应该直到里面的核心思路，就是**分段枷锁**。

把数据分成很多个段，每个段是一个单独的锁，所以多个线程过来并发修改数据的时候，可以并发的修改不同段的数据。不至于说，同一时间只能有一个线程独占修改ConcurrentHashMap 中的数据。

其实分布式锁的优化思路也是类似的。如下图：

![image-20201204112428609](C:\Users\92486\AppData\Roaming\Typora\typora-user-images\image-20201204112428609.png)

其实这就是分段加锁。加入现在iphone 有1000个库存，那么完全可以拆成20个库存段，也可以在数据库的表里建20个库存字段，比如stock_01, stock_02，类似这样的，也可以在redis 之类的地方放20个库存key。

总之，就是把1000个库存拆开，每个库存段是50件库存，比如stock_01 对应50件库存，stock_02 对应50件库存。

接着，每秒1000个请求过来了，此时其实可以使用一个简单的随机算法，每个请求都是随机在20个分段库存里，选择一个进行加锁。

这样同时就可以有最多20个下单请求一起执行，每个下单请求锁了一个库存分段，然后在业务逻辑里面，就对数据库或者是Redis 中的那个分段库存进行操作即可，包括查库存，判断库存是否充足，扣减库存。

如此一来，相当于一个20毫秒，可以并发处理掉20个下单请求，那么1秒，也就可以依次处理掉20*50 = 10000 个对iphone 的下单请求了。

注意：如果某个下单请求，加锁后发现这个分段库存里的库存不足（由于是分段，所以此时无法判断其余分段库存是否充足）。这时得自动释放锁，然后立马换下一个分段库存，再次尝试加锁后尝试处理。

### 分布式锁并发优化方案有没有什么不足？

最大的不足，就是实现过于复杂。

- 首先，得对一个数据分段存储，一个库存字段本来好好的，现在要分为20个分段库存字段
- 其次，你在每次处理库存的时候，需要自己写随机算法，随机挑选一个分段来处理
- 最后，如果某个分段中的数据不足了，得自动切换到下一个分段数据去处理

这个过程都是要手动写代码实现的，还是有点工作量的。

不过在一些业务场景中，因为用到了分布式锁，又必须要进行锁并发的优化，有进一步用到了分段加锁的技术方案，效果当然是很好的，并发性能可以增长几十倍。