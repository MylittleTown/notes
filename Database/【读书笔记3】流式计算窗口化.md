在流式计算中，数据是没有边界的，源源不断的数据从输入流向输出，但是计算是需要边界的，无论是增量计算还是全量计算，都需要一个范围。那么，把无限的数据流划分为一段一段的数据集，这个计算模型可以称为窗口模型。

（数据流对窗口模型的watermark 的影响还没有想通）

基本的窗口模型，会根据时间来划分出一个一个有范围的窗口，在此基础上对一批数据集进行计算。一般情况下，有两种必定出现的时间点，数据的发生时间（event time，事件时间）和数据处理的时间（processing time，处理时间）。

先来看一个例子，比如网页中一个事件的出发从而向后台提交了一条数据，后台把数据发到了kafka，另一端一个kafka 的消费者把数据取出来进行计算，那么数据发生时间就是该网页事件触发的时间，而数据处理时间则为最终计算这条数据的时刻。理想情况下，这两个事件是成正比关系的，也就是数据发生的越晚，那么数据处理的越晚，但由于网络波动，硬件设备故障等原因，数据总是会不按顺序的被处理，参考下图。

![数据发生时间和数据处理时间曲线](https://raw.githubusercontent.com/MylittleTown/notes/master/Linked_pictures/%E7%AC%94%E8%AE%B03-%E6%95%B0%E6%8D%AE%E5%8F%91%E7%94%9F%E6%97%B6%E9%97%B4%E5%92%8C%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4%E6%9B%B2%E7%BA%BF.png)

影响因素包括：

- 共享资源限制，例如，网络拥塞，网络分区或非专用环境中的共享CPU
- 软件原因，如分布式系统逻辑，争用等
- 数据本身的特征，包括键值分布，吞吐量变化或无序变化

在这个背景下，对时间的选择显得更加复杂。一般而言用的是数据产生的时间，更贴近业务的需求，所见即所得，否则采用数据处理的事件会导致结果不稳定。

如果关心流数据计算的正确性，并且希望在分析事件时间下的结果，就不能基于处理时间定义的时间边界。由于处理时间和事件时间之间没有一致的相关性，一些事件时间数据最终将落入错误的处理时间窗口，从而导致失去正确性。而在无界数据中，无序和可变的偏差会引发事件时间窗口的完整性，因为缺乏处理时间和事件时间之间偏差的可预测映射。

基于两种时间域的窗口化（处理时间，事件时间）：

- 处理时间窗口

  ![处理时间窗口](https://raw.githubusercontent.com/MylittleTown/notes/master/Linked_pictures/%E7%AC%94%E8%AE%B03-%E5%A4%84%E7%90%86%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3.png)

  当通过处理时间窗口化时，系统将传入数据缓冲到窗口中，直到经过了一些处理时间。例如，对于5分钟的固定窗口，系统将缓冲5分钟的处理时间，之后将把这5分钟观察到的所有数据作为窗口，将它们发送到下游进行处理。

  处理时间窗口有几个很好的特性：

  1. 实现非常简单，不必担心在时间内对数据进行洗牌。只要在数据到达时缓冲它们，并在窗口关闭时将窗口数据发送到下游。
  2. 判断窗口的完整性很容易。由于系统完全知道是否已经看到窗口的所有输入，所以可以对给定的窗口是否完整作出完美的决策。这意味着在通过处理时间打开窗口（使用窗口中数据）时，不需要以任何方式处理“延迟”数据。
  3. 如果你想根据观察结果推断关于源的信息，那么处理时间窗口正合适。许多监控场景都属于此类*（理由类同原因2，可以完整获取窗口内的数据，但是同一个源的数据流会根据key 被分到多个窗口中，且是无序的，那么会不会出现数据丢失？）*。想象一下：跟踪每秒发送给全局规模Web 服务的请求数量；为了检测停机而计算这些请求的速率是完美利用处理时间窗口。

  处理时间窗口有一个很大的缺点：如果所讨论的数据具有与相关联的事件时间，那么如果处理时间窗口要反映这些事件实际发生时的真实情况，则这些数据必须按事件时间顺序到达。不幸的是，**基于事件时间有序数据在许多真实的分布式输入源中并不常见**。

- 事件时间窗口

  ![事件时间窗口](https://raw.githubusercontent.com/MylittleTown/notes/master/Linked_pictures/%E7%AC%94%E8%AE%B03-%E4%BA%8B%E4%BB%B6%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3.png)

  当需要以有限块观察数据源，反映那些事件实际发生的时间时使用的窗口是事件时间窗口。这是窗口化的最高标准。可是，今天使用的大多数数据处理系统缺乏对它的原生支持。

  上图中的实心白线表示两个感兴趣的特定数据。这两个数据到达的处理时间窗口都与他们本该属于的事件时间窗口不匹配。因此，如果对于关心事件时间的场景，这些数据被窗口化到处理时间窗口中，计算的结果是不正确的（相对于事件时间有序的数据无法准确的在处理时间窗口中计算，因为两者没有可预测的映射）。只有正确的进入事件时间窗口的分析结果才会是正确的。

  事件时间窗口对于无限数据的另一个好处是，可以创建动态大小的窗口，例如会话，而不需要在固定窗口上生成会话进行随机的split，例如之前提到的batch split。

  事件时间窗口有两个明显的缺点，因为窗口通常必须（相比处理时间）比窗口本身的实际长度更长：

  - 缓冲区：由于窗口寿命延长，需要对数据进行更多缓冲。幸运的是，持久化存储通常是大多数数据处理系统所依赖的资源类型中最廉价的资源类型（其他主要是CPU，网络带宽和RAM）。因此，当与使用任何具有强一致性持久状态和良好内存缓存层且设计良好的数据处理系统时，这个问题通常没那么严重。而且，许多常用的聚合不需要缓冲整个输入集（例如，求和或平均值），而是可以使用更小的，以持久状态存储的中间聚合，以增量方式执行。
  - 完整性：通常没有好的方法知道何时已经看到给定窗口的所有数据，如何知道何时该窗口的结果可以具体化输出？事实上，我们根本不会。对于许多类型的输入，系统可以给出合理的相当准确的估计窗口完成时间，通过类似MillWheel 的水印（即下文提到的watermark）。但是，在要求绝对正确性的场景下，唯一的实际选择是提供给时间轴（pipeline）一种方式，表达何时结束窗口，以及如何随着时间推移而细化这些结果。

在数据不是连续的情况下，如何划分出窗口，比如每过1分钟输出一个窗口，然而数据在59秒后再也没有被接收直到几分钟后。这显然是不满足需求的，所以，引入了watermark 这个概念。

watermark 用于判定是否到达窗口的阈值，也就是产生一个窗口，watermark 会不断自我更新（即存在守护线程保证watermark 不会因为没有数据被接收而不增长）。当watermark 到达窗口的阈值，那么小于watermark 的数据会进入到该窗口。而watermark 的本质作为时间点，也分为基于数据产生时间或者数据处理时间，对应窗口化的两种方式。

基于数据产生时间，那么会导致窗口的触发时间比理想慢很多，也就是延迟大，因为数据是乱序进入的，需要等待直到数据的产生时间到达窗口阈值。

基于数据处理时间，那么会导致窗口内的数据缺失。

在定义窗口前，首先要指定数据流是否应该被分区，使用keyBy()后，相同的key 会被划分到不同的流里面，每个流可以被单独的一个task 处理。如果不使用keyBy()，所有数据会被划分到一个窗口里，只有一个task 处理，并行度为1.

在指定了数据流是否分区后，下一步是要去指定窗口的类型，Flink 预定义了很多窗口类ing，可以满足大多数日常使用需求：Tumbling windows（翻滚窗口），Sliding windows（滑动窗口），Session windows（会话窗口），Global windows（全局窗口）

1. Tumbling windows

   翻滚窗口有一个固定长度，并且不会重复。固定窗口被均匀的应用于整个数据集。在某些情况下，希望对数据的不同子集的窗口进行相位移，以便随着时间更均匀的分布窗口完成负载，比如，下图是指定了一个5分钟的翻滚窗口。

   ![翻滚窗口](https://raw.githubusercontent.com/MylittleTown/notes/master/Linked_pictures/%E7%AC%94%E8%AE%B03-%E7%BF%BB%E6%BB%9A%E7%AA%97%E5%8F%A3.png)

2. Sliding windows

   固定窗口的推广，滑动窗口由固定长度和固定周期定义。如果周期小于长度，则窗口重叠。如果周期等于长度，则变为固定窗口。如果周期大于长度，那么就变为一个采样窗口，查看随时间变化的数据子集。

   滑动窗口指定了两个参数，第一个参数是窗口大小，第二个参数控制了新的窗口开始的频率。如果滑动距离小于窗口距离的话，那么一个元素可能被分配到多个窗口中。

   比如，窗口大小为10分钟，每5分钟滑动一次，如下图：

   ![滑动窗口](https://raw.githubusercontent.com/MylittleTown/notes/master/Linked_pictures/%E7%AC%94%E8%AE%B03-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3.png)

3. Session windows

   会话由一系列事件组成的，以一个唱过inactivity gap 的时间终止。会话通常用于分析随时间变化的用户行为，通过将一系列与时间相关的事件（例如，一次连续观看的视频序列）分组在一起。会话的长度不能预先定义，取决于实际数据。会话是未对齐窗口的典型示例，因为会话在不同数据子集（例如，不同用户）之间从不相同*（Q: 会话窗口和采样窗口有什么区别呢？*）。

   会话窗口根据会话时间间隔来把数据分配到不同的窗口。会话窗口不重叠，没有固定的开始时间和结束时间。

   比如音乐APP 听歌的场景，我们想统计一个用户在一个独立的session 中听了多久的歌曲（如果超过15分钟没有听歌，那么就是一个新的session 了）

4. Global windows

   全局窗口会把所有相同key 的数据，放到一个window 中，它没有自然的窗口结束时间，需要自定义触发器。